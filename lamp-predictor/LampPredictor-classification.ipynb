{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>current</th>\n",
       "      <th>lampIsRunning</th>\n",
       "      <th>voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-05 09:19:17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-05 09:19:17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-05 09:19:17</td>\n",
       "      <td>138.933486</td>\n",
       "      <td>False</td>\n",
       "      <td>34.535565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-05 09:19:17</td>\n",
       "      <td>138.933486</td>\n",
       "      <td>True</td>\n",
       "      <td>34.535565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-05 09:19:17</td>\n",
       "      <td>139.860172</td>\n",
       "      <td>True</td>\n",
       "      <td>33.039042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp     current lampIsRunning    voltage\n",
       "0  2019-11-05 09:19:17    0.000000         False   0.000000\n",
       "1  2019-11-05 09:19:17    0.000000         False   0.000000\n",
       "2  2019-11-05 09:19:17  138.933486         False  34.535565\n",
       "3  2019-11-05 09:19:17  138.933486          True  34.535565\n",
       "4  2019-11-05 09:19:17  139.860172          True  33.039042"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"light-bulb-raw-export.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any null\n",
    "data.isnull().values.any()\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse data table\n",
    "data = data.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10676.000000</td>\n",
       "      <td>10676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>137.656154</td>\n",
       "      <td>11.695346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.068849</td>\n",
       "      <td>7.244864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120.795369</td>\n",
       "      <td>6.180031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>139.525598</td>\n",
       "      <td>11.110937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>156.446747</td>\n",
       "      <td>16.550302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>177.829100</td>\n",
       "      <td>76.108256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            current       voltage\n",
       "count  10676.000000  10676.000000\n",
       "mean     137.656154     11.695346\n",
       "std       21.068849      7.244864\n",
       "min        0.000000      0.000000\n",
       "25%      120.795369      6.180031\n",
       "50%      139.525598     11.110937\n",
       "75%      156.446747     16.550302\n",
       "max      177.829100     76.108256"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.10825644869111\n",
      "177.8291001434133\n"
     ]
    }
   ],
   "source": [
    "print(data[\"voltage\"].max())\n",
    "print(data[\"current\"].max())\n",
    "\n",
    "# normalize data\n",
    "data[\"voltage\"] = data[\"voltage\"] / data[\"voltage\"].max()\n",
    "data[\"current\"] = data[\"current\"] / data[\"current\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10676.000000</td>\n",
       "      <td>10676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.774092</td>\n",
       "      <td>0.153667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.118478</td>\n",
       "      <td>0.095192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.081201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.784605</td>\n",
       "      <td>0.145989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.879759</td>\n",
       "      <td>0.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            current       voltage\n",
       "count  10676.000000  10676.000000\n",
       "mean       0.774092      0.153667\n",
       "std        0.118478      0.095192\n",
       "min        0.000000      0.000000\n",
       "25%        0.679278      0.081201\n",
       "50%        0.784605      0.145989\n",
       "75%        0.879759      0.217457\n",
       "max        1.000000      1.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>lampIsRunning</th>\n",
       "      <th>voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>0.670266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.834433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10674</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10673</th>\n",
       "      <td>0.674805</td>\n",
       "      <td>True</td>\n",
       "      <td>0.210227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>0.675624</td>\n",
       "      <td>True</td>\n",
       "      <td>0.201216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10671</th>\n",
       "      <td>0.674761</td>\n",
       "      <td>True</td>\n",
       "      <td>0.194146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786486</td>\n",
       "      <td>True</td>\n",
       "      <td>0.434106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781275</td>\n",
       "      <td>True</td>\n",
       "      <td>0.453769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781275</td>\n",
       "      <td>False</td>\n",
       "      <td>0.453769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10676 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        current lampIsRunning   voltage\n",
       "10675  0.670266         False  0.834433\n",
       "10674  0.000000         False  0.000000\n",
       "10673  0.674805          True  0.210227\n",
       "10672  0.675624          True  0.201216\n",
       "10671  0.674761          True  0.194146\n",
       "...         ...           ...       ...\n",
       "4      0.786486          True  0.434106\n",
       "3      0.781275          True  0.453769\n",
       "2      0.781275         False  0.453769\n",
       "1      0.000000         False  0.000000\n",
       "0      0.000000         False  0.000000\n",
       "\n",
       "[10676 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete timestamp column\n",
    "data.drop(columns=\"timestamp\", inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of time to failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>lampIsRunning</th>\n",
       "      <th>voltage</th>\n",
       "      <th>failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>0.670266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.834433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10674</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10673</th>\n",
       "      <td>0.674805</td>\n",
       "      <td>True</td>\n",
       "      <td>0.210227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>0.675624</td>\n",
       "      <td>True</td>\n",
       "      <td>0.201216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10671</th>\n",
       "      <td>0.674761</td>\n",
       "      <td>True</td>\n",
       "      <td>0.194146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786486</td>\n",
       "      <td>True</td>\n",
       "      <td>0.434106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781275</td>\n",
       "      <td>True</td>\n",
       "      <td>0.453769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781275</td>\n",
       "      <td>False</td>\n",
       "      <td>0.453769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10676 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        current lampIsRunning   voltage  failure\n",
       "10675  0.670266         False  0.834433        1\n",
       "10674  0.000000         False  0.000000        1\n",
       "10673  0.674805          True  0.210227        0\n",
       "10672  0.675624          True  0.201216        0\n",
       "10671  0.674761          True  0.194146        0\n",
       "...         ...           ...       ...      ...\n",
       "4      0.786486          True  0.434106        0\n",
       "3      0.781275          True  0.453769        0\n",
       "2      0.781275         False  0.453769        1\n",
       "1      0.000000         False  0.000000        1\n",
       "0      0.000000         False  0.000000        1\n",
       "\n",
       "[10676 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['failure'] = (data['lampIsRunning'] == False).astype(int)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>voltage</th>\n",
       "      <th>failure</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10676.000000</td>\n",
       "      <td>10676.000000</td>\n",
       "      <td>10676.000000</td>\n",
       "      <td>10676.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.774092</td>\n",
       "      <td>0.153667</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>4672.209442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.118478</td>\n",
       "      <td>0.095192</td>\n",
       "      <td>0.041029</td>\n",
       "      <td>3033.832973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.679278</td>\n",
       "      <td>0.081201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1972.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.784605</td>\n",
       "      <td>0.145989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4641.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.879759</td>\n",
       "      <td>0.217457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7310.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9979.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            current       voltage       failure           ttf\n",
       "count  10676.000000  10676.000000  10676.000000  10676.000000\n",
       "mean       0.774092      0.153667      0.001686   4672.209442\n",
       "std        0.118478      0.095192      0.041029   3033.832973\n",
       "min        0.000000      0.000000      0.000000      0.000000\n",
       "25%        0.679278      0.081201      0.000000   1972.750000\n",
       "50%        0.784605      0.145989      0.000000   4641.500000\n",
       "75%        0.879759      0.217457      0.000000   7310.250000\n",
       "max        1.000000      1.000000      1.000000   9979.000000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = data['failure'].iloc[::-1].cumsum()\n",
    "data['ttf'] = s.groupby(s).cumcount()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>voltage</th>\n",
       "      <th>failure</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.601270</td>\n",
       "      <td>0.308219</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>48.612963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.178495</td>\n",
       "      <td>0.136120</td>\n",
       "      <td>0.179672</td>\n",
       "      <td>34.037852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.547877</td>\n",
       "      <td>0.237589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.631695</td>\n",
       "      <td>0.272342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.693756</td>\n",
       "      <td>0.326006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.793102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          current     voltage     failure         ttf\n",
       "count  540.000000  540.000000  540.000000  540.000000\n",
       "mean     0.601270    0.308219    0.033333   48.612963\n",
       "std      0.178495    0.136120    0.179672   34.037852\n",
       "min      0.000000    0.000000    0.000000    0.000000\n",
       "25%      0.547877    0.237589    0.000000   20.000000\n",
       "50%      0.631695    0.272342    0.000000   43.000000\n",
       "75%      0.693756    0.326006    0.000000   74.250000\n",
       "max      0.793102    1.000000    1.000000  119.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['ttf'] < 120]\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gralakj\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>voltage</th>\n",
       "      <th>ttf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>0.670266</td>\n",
       "      <td>0.834433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10674</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10673</th>\n",
       "      <td>0.674805</td>\n",
       "      <td>0.210227</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10672</th>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.201216</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10671</th>\n",
       "      <td>0.674761</td>\n",
       "      <td>0.194146</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        current   voltage  ttf\n",
       "10675  0.670266  0.834433    0\n",
       "10674  0.000000  0.000000    0\n",
       "10673  0.674805  0.210227   40\n",
       "10672  0.675624  0.201216   39\n",
       "10671  0.674761  0.194146   38"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=\"failure\", inplace=True)\n",
    "data.drop(columns=\"lampIsRunning\", inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x18ad1255a88>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sbs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sbs.distplot(data['ttf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gralakj\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "data['ttf_label'] = np.where(data['ttf'] > 90, '>90s',\n",
    "                    np.where(data['ttf'] > 60, '>60s',\n",
    "                    np.where(data['ttf'] > 30, '30-60s',\n",
    "                    np.where(data['ttf'] > 10, '10-30s', '<10s'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x18ad1262748>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.tail()\n",
    "sbs.catplot(y=\"ttf_label\", data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>voltage</th>\n",
       "      <th>ttf</th>\n",
       "      <th>ttf_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.786486</td>\n",
       "      <td>0.434106</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781275</td>\n",
       "      <td>0.453769</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.781275</td>\n",
       "      <td>0.453769</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;10s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    current   voltage  ttf ttf_label\n",
       "4  0.786486  0.434106    2      <10s\n",
       "3  0.781275  0.453769    1      <10s\n",
       "2  0.781275  0.453769    0      <10s\n",
       "1  0.000000  0.000000    0      <10s\n",
       "0  0.000000  0.000000    0      <10s"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.12, 0.22],\n",
       "        [0.12, 0.22],\n",
       "        [0.  , 0.22],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.22],\n",
       "        [0.  , 0.  ],\n",
       "        [0.73, 0.24],\n",
       "        [0.73, 0.26],\n",
       "        [0.74, 0.26],\n",
       "        [0.74, 0.27],\n",
       "        [0.74, 0.27],\n",
       "        [0.74, 0.27],\n",
       "        [0.74, 0.26],\n",
       "        [0.74, 0.27],\n",
       "        [0.74, 0.27],\n",
       "        [0.74, 0.26],\n",
       "        [0.74, 0.27],\n",
       "        [0.75, 0.27],\n",
       "        [0.75, 0.27],\n",
       "        [0.75, 0.28]]), '>90s']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "LOOKBACK_SIZE = 20\n",
    "\n",
    "seq_data = []\n",
    "prev_data = deque(maxlen=LOOKBACK_SIZE)\n",
    "\n",
    "for row in data.values:\n",
    "    prev_data.append([columns for columns in row[:-2]])\n",
    "    if len(prev_data) == LOOKBACK_SIZE:\n",
    "        seq_data.append([np.array(prev_data), row[-1]])\n",
    "\n",
    "\n",
    "random.shuffle(seq_data)\n",
    "       \n",
    "seq_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "y_dict= { \n",
    "    \"<10s\": [1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    \"10-30s\":[0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "    \"30-60s\":[0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "    \">60s\":[0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "    \">90s\":[0.0, 0.0, 0.0, 0.0, 1.0]\n",
    "}\n",
    "\n",
    "for seq, target in seq_data:\n",
    "    X.append(seq.ravel())  # seq.flatten() should work as well\n",
    "    y.append(y_dict[target])\n",
    "\n",
    "train_x = np.array(X)\n",
    "train_y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_test, y, y_test = train_test_split(train_x, train_y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 40)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X,y  - zbiór uczacy\n",
    "# X_test, y_test - zbiór testujacy\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 279 samples, validate on 70 samples\n",
      "Epoch 1/1000\n",
      "279/279 [==============================] - 0s 689us/step - loss: 1.5809 - accuracy: 0.3047 - val_loss: 1.5622 - val_accuracy: 0.4286\n",
      "Epoch 2/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 1.5413 - accuracy: 0.3477 - val_loss: 1.5450 - val_accuracy: 0.3714\n",
      "Epoch 3/1000\n",
      "279/279 [==============================] - 0s 82us/step - loss: 1.5189 - accuracy: 0.3656 - val_loss: 1.5180 - val_accuracy: 0.4286\n",
      "Epoch 4/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 1.5007 - accuracy: 0.3620 - val_loss: 1.4800 - val_accuracy: 0.4286\n",
      "Epoch 5/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.4819 - accuracy: 0.3620 - val_loss: 1.4797 - val_accuracy: 0.4429\n",
      "Epoch 6/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 1.4654 - accuracy: 0.3728 - val_loss: 1.4485 - val_accuracy: 0.4286\n",
      "Epoch 7/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 1.4488 - accuracy: 0.3763 - val_loss: 1.4316 - val_accuracy: 0.4286\n",
      "Epoch 8/1000\n",
      "279/279 [==============================] - 0s 97us/step - loss: 1.4323 - accuracy: 0.3799 - val_loss: 1.4183 - val_accuracy: 0.4286\n",
      "Epoch 9/1000\n",
      "279/279 [==============================] - 0s 119us/step - loss: 1.4197 - accuracy: 0.3871 - val_loss: 1.3925 - val_accuracy: 0.4429\n",
      "Epoch 10/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.4052 - accuracy: 0.3835 - val_loss: 1.3907 - val_accuracy: 0.4429\n",
      "Epoch 11/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 1.3954 - accuracy: 0.3835 - val_loss: 1.3751 - val_accuracy: 0.4429\n",
      "Epoch 12/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 1.3814 - accuracy: 0.3728 - val_loss: 1.3639 - val_accuracy: 0.4286\n",
      "Epoch 13/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 1.3708 - accuracy: 0.3978 - val_loss: 1.3590 - val_accuracy: 0.4429\n",
      "Epoch 14/1000\n",
      "279/279 [==============================] - 0s 82us/step - loss: 1.3610 - accuracy: 0.4158 - val_loss: 1.3362 - val_accuracy: 0.4571\n",
      "Epoch 15/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 1.3539 - accuracy: 0.4014 - val_loss: 1.3540 - val_accuracy: 0.4429\n",
      "Epoch 16/1000\n",
      "279/279 [==============================] - 0s 95us/step - loss: 1.3546 - accuracy: 0.4122 - val_loss: 1.3229 - val_accuracy: 0.4714\n",
      "Epoch 17/1000\n",
      "279/279 [==============================] - 0s 124us/step - loss: 1.3370 - accuracy: 0.4229 - val_loss: 1.3387 - val_accuracy: 0.4429\n",
      "Epoch 18/1000\n",
      "279/279 [==============================] - 0s 111us/step - loss: 1.3315 - accuracy: 0.4122 - val_loss: 1.3208 - val_accuracy: 0.4714\n",
      "Epoch 19/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 1.3167 - accuracy: 0.4158 - val_loss: 1.3209 - val_accuracy: 0.4429\n",
      "Epoch 20/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 1.3110 - accuracy: 0.4158 - val_loss: 1.3118 - val_accuracy: 0.4286\n",
      "Epoch 21/1000\n",
      "279/279 [==============================] - 0s 85us/step - loss: 1.3077 - accuracy: 0.4229 - val_loss: 1.2941 - val_accuracy: 0.4714\n",
      "Epoch 22/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 1.2980 - accuracy: 0.4194 - val_loss: 1.3120 - val_accuracy: 0.4143\n",
      "Epoch 23/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 1.2871 - accuracy: 0.4265 - val_loss: 1.2934 - val_accuracy: 0.4714\n",
      "Epoch 24/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 1.2780 - accuracy: 0.4337 - val_loss: 1.2902 - val_accuracy: 0.4714\n",
      "Epoch 25/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 1.2676 - accuracy: 0.4301 - val_loss: 1.2914 - val_accuracy: 0.4000\n",
      "Epoch 26/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 1.2689 - accuracy: 0.4588 - val_loss: 1.2812 - val_accuracy: 0.4143\n",
      "Epoch 27/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 1.2711 - accuracy: 0.4265 - val_loss: 1.3014 - val_accuracy: 0.4714\n",
      "Epoch 28/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 1.2614 - accuracy: 0.4444 - val_loss: 1.2572 - val_accuracy: 0.4714\n",
      "Epoch 29/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 1.2543 - accuracy: 0.4337 - val_loss: 1.3016 - val_accuracy: 0.4571\n",
      "Epoch 30/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 1.2385 - accuracy: 0.4122 - val_loss: 1.2590 - val_accuracy: 0.4857\n",
      "Epoch 31/1000\n",
      "279/279 [==============================] - 0s 104us/step - loss: 1.2343 - accuracy: 0.4659 - val_loss: 1.2639 - val_accuracy: 0.5143\n",
      "Epoch 32/1000\n",
      "279/279 [==============================] - 0s 101us/step - loss: 1.2231 - accuracy: 0.4767 - val_loss: 1.2520 - val_accuracy: 0.4714\n",
      "Epoch 33/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 1.2230 - accuracy: 0.4731 - val_loss: 1.2621 - val_accuracy: 0.4857\n",
      "Epoch 34/1000\n",
      "279/279 [==============================] - 0s 93us/step - loss: 1.2167 - accuracy: 0.4910 - val_loss: 1.2710 - val_accuracy: 0.5143\n",
      "Epoch 35/1000\n",
      "279/279 [==============================] - 0s 93us/step - loss: 1.2077 - accuracy: 0.5412 - val_loss: 1.2554 - val_accuracy: 0.5286\n",
      "Epoch 36/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 1.2021 - accuracy: 0.4624 - val_loss: 1.2479 - val_accuracy: 0.5000\n",
      "Epoch 37/1000\n",
      "279/279 [==============================] - 0s 78us/step - loss: 1.1926 - accuracy: 0.4552 - val_loss: 1.2654 - val_accuracy: 0.5429\n",
      "Epoch 38/1000\n",
      "279/279 [==============================] - 0s 96us/step - loss: 1.1899 - accuracy: 0.5376 - val_loss: 1.2594 - val_accuracy: 0.4429\n",
      "Epoch 39/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.1845 - accuracy: 0.4910 - val_loss: 1.2522 - val_accuracy: 0.5286\n",
      "Epoch 40/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 1.1790 - accuracy: 0.5197 - val_loss: 1.2599 - val_accuracy: 0.4714\n",
      "Epoch 41/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 1.1771 - accuracy: 0.5054 - val_loss: 1.2442 - val_accuracy: 0.4429\n",
      "Epoch 42/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 1.1736 - accuracy: 0.4875 - val_loss: 1.2560 - val_accuracy: 0.5429\n",
      "Epoch 43/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.1628 - accuracy: 0.4875 - val_loss: 1.2437 - val_accuracy: 0.5286\n",
      "Epoch 44/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 1.1648 - accuracy: 0.5161 - val_loss: 1.2494 - val_accuracy: 0.5286\n",
      "Epoch 45/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 1.1630 - accuracy: 0.4982 - val_loss: 1.2552 - val_accuracy: 0.5429\n",
      "Epoch 46/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.1537 - accuracy: 0.5269 - val_loss: 1.2297 - val_accuracy: 0.4571\n",
      "Epoch 47/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.1489 - accuracy: 0.5161 - val_loss: 1.2699 - val_accuracy: 0.5286\n",
      "Epoch 48/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.1512 - accuracy: 0.4982 - val_loss: 1.2442 - val_accuracy: 0.5429\n",
      "Epoch 49/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 1.1458 - accuracy: 0.5376 - val_loss: 1.2558 - val_accuracy: 0.5429\n",
      "Epoch 50/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 1.1573 - accuracy: 0.5269 - val_loss: 1.2368 - val_accuracy: 0.4571\n",
      "Epoch 51/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 1.1522 - accuracy: 0.4731 - val_loss: 1.3007 - val_accuracy: 0.4714\n",
      "Epoch 52/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 1.1483 - accuracy: 0.4946 - val_loss: 1.2388 - val_accuracy: 0.5143\n",
      "Epoch 53/1000\n",
      "279/279 [==============================] - 0s 92us/step - loss: 1.1247 - accuracy: 0.5484 - val_loss: 1.2566 - val_accuracy: 0.5429\n",
      "Epoch 54/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 1.1185 - accuracy: 0.5591 - val_loss: 1.2417 - val_accuracy: 0.5429\n",
      "Epoch 55/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 1.1286 - accuracy: 0.5125 - val_loss: 1.2470 - val_accuracy: 0.5000\n",
      "Epoch 56/1000\n",
      "279/279 [==============================] - 0s 93us/step - loss: 1.1152 - accuracy: 0.5233 - val_loss: 1.2659 - val_accuracy: 0.5571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 1.1168 - accuracy: 0.5305 - val_loss: 1.2273 - val_accuracy: 0.5286\n",
      "Epoch 58/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.1071 - accuracy: 0.5161 - val_loss: 1.2493 - val_accuracy: 0.5429\n",
      "Epoch 59/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 1.1004 - accuracy: 0.5556 - val_loss: 1.2609 - val_accuracy: 0.5143\n",
      "Epoch 60/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 1.0948 - accuracy: 0.5520 - val_loss: 1.2288 - val_accuracy: 0.5429\n",
      "Epoch 61/1000\n",
      "279/279 [==============================] - 0s 58us/step - loss: 1.0920 - accuracy: 0.5627 - val_loss: 1.2597 - val_accuracy: 0.5429\n",
      "Epoch 62/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.0904 - accuracy: 0.5591 - val_loss: 1.2275 - val_accuracy: 0.5143\n",
      "Epoch 63/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.0872 - accuracy: 0.5806 - val_loss: 1.2714 - val_accuracy: 0.5571\n",
      "Epoch 64/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 1.0789 - accuracy: 0.5771 - val_loss: 1.2409 - val_accuracy: 0.4857\n",
      "Epoch 65/1000\n",
      "279/279 [==============================] - 0s 85us/step - loss: 1.0807 - accuracy: 0.5556 - val_loss: 1.2572 - val_accuracy: 0.4714\n",
      "Epoch 66/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 1.0775 - accuracy: 0.5484 - val_loss: 1.2561 - val_accuracy: 0.5429\n",
      "Epoch 67/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.0833 - accuracy: 0.5591 - val_loss: 1.2515 - val_accuracy: 0.5286\n",
      "Epoch 68/1000\n",
      "279/279 [==============================] - 0s 93us/step - loss: 1.0702 - accuracy: 0.5771 - val_loss: 1.2499 - val_accuracy: 0.5429\n",
      "Epoch 69/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 1.0608 - accuracy: 0.5806 - val_loss: 1.2608 - val_accuracy: 0.5286\n",
      "Epoch 70/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.0611 - accuracy: 0.5735 - val_loss: 1.2603 - val_accuracy: 0.5143\n",
      "Epoch 71/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 1.0592 - accuracy: 0.5806 - val_loss: 1.2448 - val_accuracy: 0.5286\n",
      "Epoch 72/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.0563 - accuracy: 0.5591 - val_loss: 1.2520 - val_accuracy: 0.5429\n",
      "Epoch 73/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.0521 - accuracy: 0.5806 - val_loss: 1.2670 - val_accuracy: 0.5429\n",
      "Epoch 74/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 1.0442 - accuracy: 0.5771 - val_loss: 1.2523 - val_accuracy: 0.5143\n",
      "Epoch 75/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 1.0446 - accuracy: 0.5842 - val_loss: 1.2617 - val_accuracy: 0.5429\n",
      "Epoch 76/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 1.0502 - accuracy: 0.5520 - val_loss: 1.2607 - val_accuracy: 0.4857\n",
      "Epoch 77/1000\n",
      "279/279 [==============================] - 0s 57us/step - loss: 1.0605 - accuracy: 0.5269 - val_loss: 1.2839 - val_accuracy: 0.5286\n",
      "Epoch 78/1000\n",
      "279/279 [==============================] - 0s 59us/step - loss: 1.0457 - accuracy: 0.5842 - val_loss: 1.2573 - val_accuracy: 0.5286\n",
      "Epoch 79/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 1.0315 - accuracy: 0.5986 - val_loss: 1.2875 - val_accuracy: 0.5000\n",
      "Epoch 80/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 1.0335 - accuracy: 0.5950 - val_loss: 1.2433 - val_accuracy: 0.5286\n",
      "Epoch 81/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.0422 - accuracy: 0.5520 - val_loss: 1.3203 - val_accuracy: 0.5286\n",
      "Epoch 82/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 1.0496 - accuracy: 0.5269 - val_loss: 1.2674 - val_accuracy: 0.5286\n",
      "Epoch 83/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 1.0368 - accuracy: 0.5627 - val_loss: 1.2705 - val_accuracy: 0.5286\n",
      "Epoch 84/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.0214 - accuracy: 0.5878 - val_loss: 1.2943 - val_accuracy: 0.5000\n",
      "Epoch 85/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 1.0292 - accuracy: 0.5950 - val_loss: 1.2818 - val_accuracy: 0.5286\n",
      "Epoch 86/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 1.0183 - accuracy: 0.5591 - val_loss: 1.3057 - val_accuracy: 0.5286\n",
      "Epoch 87/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 1.0221 - accuracy: 0.5950 - val_loss: 1.2720 - val_accuracy: 0.5143\n",
      "Epoch 88/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 1.0087 - accuracy: 0.5950 - val_loss: 1.2816 - val_accuracy: 0.5286\n",
      "Epoch 89/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 1.0031 - accuracy: 0.5914 - val_loss: 1.2732 - val_accuracy: 0.5286\n",
      "Epoch 90/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.0057 - accuracy: 0.5842 - val_loss: 1.2731 - val_accuracy: 0.5143\n",
      "Epoch 91/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 1.0071 - accuracy: 0.5663 - val_loss: 1.2709 - val_accuracy: 0.5143\n",
      "Epoch 92/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.9939 - accuracy: 0.5950 - val_loss: 1.2865 - val_accuracy: 0.5143\n",
      "Epoch 93/1000\n",
      "279/279 [==============================] - 0s 64us/step - loss: 0.9927 - accuracy: 0.6057 - val_loss: 1.2775 - val_accuracy: 0.5429\n",
      "Epoch 94/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9946 - accuracy: 0.6093 - val_loss: 1.3296 - val_accuracy: 0.5429\n",
      "Epoch 95/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.9898 - accuracy: 0.5986 - val_loss: 1.2561 - val_accuracy: 0.5286\n",
      "Epoch 96/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 1.0125 - accuracy: 0.6129 - val_loss: 1.3553 - val_accuracy: 0.5429\n",
      "Epoch 97/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 1.0297 - accuracy: 0.5627 - val_loss: 1.3005 - val_accuracy: 0.4857\n",
      "Epoch 98/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 1.0300 - accuracy: 0.5556 - val_loss: 1.3680 - val_accuracy: 0.4571\n",
      "Epoch 99/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 1.0282 - accuracy: 0.5735 - val_loss: 1.3176 - val_accuracy: 0.4857\n",
      "Epoch 100/1000\n",
      "279/279 [==============================] - 0s 95us/step - loss: 0.9887 - accuracy: 0.5950 - val_loss: 1.2623 - val_accuracy: 0.5286\n",
      "Epoch 101/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9786 - accuracy: 0.5878 - val_loss: 1.3228 - val_accuracy: 0.5143\n",
      "Epoch 102/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.9998 - accuracy: 0.5520 - val_loss: 1.2926 - val_accuracy: 0.4571\n",
      "Epoch 103/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.9762 - accuracy: 0.6022 - val_loss: 1.3183 - val_accuracy: 0.5000\n",
      "Epoch 104/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.9874 - accuracy: 0.5914 - val_loss: 1.2998 - val_accuracy: 0.4857\n",
      "Epoch 105/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9674 - accuracy: 0.5986 - val_loss: 1.2900 - val_accuracy: 0.5000\n",
      "Epoch 106/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.9762 - accuracy: 0.5842 - val_loss: 1.2961 - val_accuracy: 0.5429\n",
      "Epoch 107/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9838 - accuracy: 0.5842 - val_loss: 1.3074 - val_accuracy: 0.5286\n",
      "Epoch 108/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.9897 - accuracy: 0.5699 - val_loss: 1.3611 - val_accuracy: 0.5000\n",
      "Epoch 109/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9979 - accuracy: 0.5842 - val_loss: 1.2834 - val_accuracy: 0.5143\n",
      "Epoch 110/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.9787 - accuracy: 0.5986 - val_loss: 1.3404 - val_accuracy: 0.5429\n",
      "Epoch 111/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9741 - accuracy: 0.6165 - val_loss: 1.2921 - val_accuracy: 0.5429\n",
      "Epoch 112/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.9481 - accuracy: 0.6344 - val_loss: 1.2819 - val_accuracy: 0.5571\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 0s 85us/step - loss: 0.9533 - accuracy: 0.6129 - val_loss: 1.3184 - val_accuracy: 0.5000\n",
      "Epoch 114/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.9519 - accuracy: 0.6129 - val_loss: 1.2976 - val_accuracy: 0.5429\n",
      "Epoch 115/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9619 - accuracy: 0.6487 - val_loss: 1.3016 - val_accuracy: 0.5571\n",
      "Epoch 116/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9599 - accuracy: 0.6237 - val_loss: 1.3536 - val_accuracy: 0.5286\n",
      "Epoch 117/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9723 - accuracy: 0.5914 - val_loss: 1.3129 - val_accuracy: 0.5571\n",
      "Epoch 118/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9929 - accuracy: 0.5842 - val_loss: 1.3522 - val_accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "279/279 [==============================] - 0s 54us/step - loss: 0.9773 - accuracy: 0.6129 - val_loss: 1.3535 - val_accuracy: 0.5000\n",
      "Epoch 120/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9603 - accuracy: 0.6129 - val_loss: 1.3024 - val_accuracy: 0.5286\n",
      "Epoch 121/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.9434 - accuracy: 0.6416 - val_loss: 1.2791 - val_accuracy: 0.5286\n",
      "Epoch 122/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.9317 - accuracy: 0.6165 - val_loss: 1.3104 - val_accuracy: 0.5286\n",
      "Epoch 123/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9321 - accuracy: 0.6272 - val_loss: 1.3173 - val_accuracy: 0.5286\n",
      "Epoch 124/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.9363 - accuracy: 0.6416 - val_loss: 1.2980 - val_accuracy: 0.5571\n",
      "Epoch 125/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9468 - accuracy: 0.5914 - val_loss: 1.3268 - val_accuracy: 0.5143\n",
      "Epoch 126/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.9317 - accuracy: 0.6237 - val_loss: 1.2988 - val_accuracy: 0.5714\n",
      "Epoch 127/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.9271 - accuracy: 0.6272 - val_loss: 1.3340 - val_accuracy: 0.5286\n",
      "Epoch 128/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9170 - accuracy: 0.6380 - val_loss: 1.3242 - val_accuracy: 0.5429\n",
      "Epoch 129/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.9401 - accuracy: 0.6129 - val_loss: 1.3060 - val_accuracy: 0.5714\n",
      "Epoch 130/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.9325 - accuracy: 0.6344 - val_loss: 1.3502 - val_accuracy: 0.5429\n",
      "Epoch 131/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9250 - accuracy: 0.6057 - val_loss: 1.2983 - val_accuracy: 0.5714\n",
      "Epoch 132/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9135 - accuracy: 0.6703 - val_loss: 1.3212 - val_accuracy: 0.5143\n",
      "Epoch 133/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9103 - accuracy: 0.6631 - val_loss: 1.3237 - val_accuracy: 0.5286\n",
      "Epoch 134/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9261 - accuracy: 0.6416 - val_loss: 1.3153 - val_accuracy: 0.5714\n",
      "Epoch 135/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9152 - accuracy: 0.6559 - val_loss: 1.3564 - val_accuracy: 0.5000\n",
      "Epoch 136/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9167 - accuracy: 0.6595 - val_loss: 1.3229 - val_accuracy: 0.5571\n",
      "Epoch 137/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9176 - accuracy: 0.6487 - val_loss: 1.3590 - val_accuracy: 0.5000\n",
      "Epoch 138/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9107 - accuracy: 0.6272 - val_loss: 1.3299 - val_accuracy: 0.5857\n",
      "Epoch 139/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9201 - accuracy: 0.6093 - val_loss: 1.3607 - val_accuracy: 0.5143\n",
      "Epoch 140/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.9304 - accuracy: 0.6237 - val_loss: 1.3503 - val_accuracy: 0.5143\n",
      "Epoch 141/1000\n",
      "279/279 [==============================] - 0s 97us/step - loss: 0.9128 - accuracy: 0.6344 - val_loss: 1.2948 - val_accuracy: 0.5714\n",
      "Epoch 142/1000\n",
      "279/279 [==============================] - 0s 101us/step - loss: 0.8992 - accuracy: 0.6344 - val_loss: 1.3680 - val_accuracy: 0.5571\n",
      "Epoch 143/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.9109 - accuracy: 0.6452 - val_loss: 1.3112 - val_accuracy: 0.5714\n",
      "Epoch 144/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.8903 - accuracy: 0.6846 - val_loss: 1.3464 - val_accuracy: 0.5286\n",
      "Epoch 145/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.8964 - accuracy: 0.6093 - val_loss: 1.3089 - val_accuracy: 0.5714\n",
      "Epoch 146/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.8997 - accuracy: 0.6882 - val_loss: 1.3202 - val_accuracy: 0.5714\n",
      "Epoch 147/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.9007 - accuracy: 0.6452 - val_loss: 1.3116 - val_accuracy: 0.5571\n",
      "Epoch 148/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.9060 - accuracy: 0.6165 - val_loss: 1.3535 - val_accuracy: 0.5143\n",
      "Epoch 149/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8857 - accuracy: 0.6523 - val_loss: 1.3207 - val_accuracy: 0.5571\n",
      "Epoch 150/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.8802 - accuracy: 0.6452 - val_loss: 1.3569 - val_accuracy: 0.5571\n",
      "Epoch 151/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8987 - accuracy: 0.6380 - val_loss: 1.3167 - val_accuracy: 0.5429\n",
      "Epoch 152/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8985 - accuracy: 0.6631 - val_loss: 1.3351 - val_accuracy: 0.5714\n",
      "Epoch 153/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.8801 - accuracy: 0.6703 - val_loss: 1.3187 - val_accuracy: 0.5714\n",
      "Epoch 154/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8752 - accuracy: 0.6846 - val_loss: 1.3120 - val_accuracy: 0.5571\n",
      "Epoch 155/1000\n",
      "279/279 [==============================] - 0s 78us/step - loss: 0.8686 - accuracy: 0.6810 - val_loss: 1.3064 - val_accuracy: 0.5571\n",
      "Epoch 156/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8780 - accuracy: 0.6595 - val_loss: 1.3063 - val_accuracy: 0.5571\n",
      "Epoch 157/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.8669 - accuracy: 0.6846 - val_loss: 1.3194 - val_accuracy: 0.5857\n",
      "Epoch 158/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.8626 - accuracy: 0.6667 - val_loss: 1.3203 - val_accuracy: 0.5714\n",
      "Epoch 159/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8702 - accuracy: 0.6774 - val_loss: 1.3108 - val_accuracy: 0.6000\n",
      "Epoch 160/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.9037 - accuracy: 0.6559 - val_loss: 1.3930 - val_accuracy: 0.5000\n",
      "Epoch 161/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.8891 - accuracy: 0.6595 - val_loss: 1.2814 - val_accuracy: 0.5714\n",
      "Epoch 162/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.8684 - accuracy: 0.6523 - val_loss: 1.3448 - val_accuracy: 0.5429\n",
      "Epoch 163/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8654 - accuracy: 0.6846 - val_loss: 1.3392 - val_accuracy: 0.5571\n",
      "Epoch 164/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.8674 - accuracy: 0.6774 - val_loss: 1.3599 - val_accuracy: 0.5571\n",
      "Epoch 165/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8676 - accuracy: 0.6452 - val_loss: 1.2884 - val_accuracy: 0.5571\n",
      "Epoch 166/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.8525 - accuracy: 0.6918 - val_loss: 1.3621 - val_accuracy: 0.5143\n",
      "Epoch 167/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.8529 - accuracy: 0.6631 - val_loss: 1.3027 - val_accuracy: 0.6000\n",
      "Epoch 168/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8497 - accuracy: 0.6882 - val_loss: 1.3525 - val_accuracy: 0.5571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.8569 - accuracy: 0.6703 - val_loss: 1.3114 - val_accuracy: 0.5714\n",
      "Epoch 170/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8647 - accuracy: 0.6416 - val_loss: 1.3247 - val_accuracy: 0.5714\n",
      "Epoch 171/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.8582 - accuracy: 0.6595 - val_loss: 1.3346 - val_accuracy: 0.5571\n",
      "Epoch 172/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.8752 - accuracy: 0.6237 - val_loss: 1.2958 - val_accuracy: 0.5857\n",
      "Epoch 173/1000\n",
      "279/279 [==============================] - 0s 57us/step - loss: 0.8493 - accuracy: 0.6416 - val_loss: 1.3308 - val_accuracy: 0.5286\n",
      "Epoch 174/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8441 - accuracy: 0.6953 - val_loss: 1.2913 - val_accuracy: 0.5857\n",
      "Epoch 175/1000\n",
      "279/279 [==============================] - 0s 59us/step - loss: 0.8583 - accuracy: 0.6703 - val_loss: 1.3206 - val_accuracy: 0.6000\n",
      "Epoch 176/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.8484 - accuracy: 0.6953 - val_loss: 1.3280 - val_accuracy: 0.5571\n",
      "Epoch 177/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.8453 - accuracy: 0.6846 - val_loss: 1.3010 - val_accuracy: 0.5857\n",
      "Epoch 178/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8403 - accuracy: 0.6810 - val_loss: 1.2818 - val_accuracy: 0.5286\n",
      "Epoch 179/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.8294 - accuracy: 0.6703 - val_loss: 1.3061 - val_accuracy: 0.5857\n",
      "Epoch 180/1000\n",
      "279/279 [==============================] - 0s 58us/step - loss: 0.8329 - accuracy: 0.6810 - val_loss: 1.3066 - val_accuracy: 0.5714\n",
      "Epoch 181/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.8568 - accuracy: 0.6631 - val_loss: 1.2901 - val_accuracy: 0.5571\n",
      "Epoch 182/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8327 - accuracy: 0.6416 - val_loss: 1.3398 - val_accuracy: 0.6000\n",
      "Epoch 183/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.8545 - accuracy: 0.6846 - val_loss: 1.2877 - val_accuracy: 0.5571\n",
      "Epoch 184/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.8287 - accuracy: 0.6631 - val_loss: 1.3006 - val_accuracy: 0.6000\n",
      "Epoch 185/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.8334 - accuracy: 0.6882 - val_loss: 1.2985 - val_accuracy: 0.5286\n",
      "Epoch 186/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.8358 - accuracy: 0.7025 - val_loss: 1.2764 - val_accuracy: 0.5714\n",
      "Epoch 187/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8356 - accuracy: 0.6344 - val_loss: 1.3033 - val_accuracy: 0.5714\n",
      "Epoch 188/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.8364 - accuracy: 0.7133 - val_loss: 1.2777 - val_accuracy: 0.6000\n",
      "Epoch 189/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.8220 - accuracy: 0.6774 - val_loss: 1.2627 - val_accuracy: 0.5714\n",
      "Epoch 190/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8132 - accuracy: 0.6846 - val_loss: 1.3206 - val_accuracy: 0.5571\n",
      "Epoch 191/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.8121 - accuracy: 0.6918 - val_loss: 1.2674 - val_accuracy: 0.5857\n",
      "Epoch 192/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.8258 - accuracy: 0.6882 - val_loss: 1.3618 - val_accuracy: 0.5429\n",
      "Epoch 193/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8365 - accuracy: 0.6738 - val_loss: 1.2725 - val_accuracy: 0.6000\n",
      "Epoch 194/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8530 - accuracy: 0.6523 - val_loss: 1.3705 - val_accuracy: 0.5286\n",
      "Epoch 195/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.8647 - accuracy: 0.6918 - val_loss: 1.2920 - val_accuracy: 0.6000\n",
      "Epoch 196/1000\n",
      "279/279 [==============================] - 0s 64us/step - loss: 0.8224 - accuracy: 0.6846 - val_loss: 1.2656 - val_accuracy: 0.5714\n",
      "Epoch 197/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.8279 - accuracy: 0.6703 - val_loss: 1.3165 - val_accuracy: 0.5571\n",
      "Epoch 198/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.8179 - accuracy: 0.6559 - val_loss: 1.2535 - val_accuracy: 0.5714\n",
      "Epoch 199/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.8064 - accuracy: 0.6953 - val_loss: 1.2518 - val_accuracy: 0.5571\n",
      "Epoch 200/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.7985 - accuracy: 0.6703 - val_loss: 1.2252 - val_accuracy: 0.6000\n",
      "Epoch 201/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7983 - accuracy: 0.6953 - val_loss: 1.2586 - val_accuracy: 0.5857\n",
      "Epoch 202/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8035 - accuracy: 0.7168 - val_loss: 1.2331 - val_accuracy: 0.5571\n",
      "Epoch 203/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.8048 - accuracy: 0.6774 - val_loss: 1.2615 - val_accuracy: 0.6000\n",
      "Epoch 204/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.7979 - accuracy: 0.6882 - val_loss: 1.2343 - val_accuracy: 0.5714\n",
      "Epoch 205/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.8136 - accuracy: 0.6774 - val_loss: 1.2656 - val_accuracy: 0.5857\n",
      "Epoch 206/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.8024 - accuracy: 0.6810 - val_loss: 1.2621 - val_accuracy: 0.6000\n",
      "Epoch 207/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.8009 - accuracy: 0.6810 - val_loss: 1.2476 - val_accuracy: 0.6000\n",
      "Epoch 208/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.7953 - accuracy: 0.7097 - val_loss: 1.2662 - val_accuracy: 0.5857\n",
      "Epoch 209/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.7954 - accuracy: 0.6595 - val_loss: 1.2261 - val_accuracy: 0.5714\n",
      "Epoch 210/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.8000 - accuracy: 0.6953 - val_loss: 1.2661 - val_accuracy: 0.5857\n",
      "Epoch 211/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.7953 - accuracy: 0.6703 - val_loss: 1.2120 - val_accuracy: 0.6286\n",
      "Epoch 212/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.7812 - accuracy: 0.6953 - val_loss: 1.2285 - val_accuracy: 0.6000\n",
      "Epoch 213/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.7698 - accuracy: 0.7025 - val_loss: 1.2518 - val_accuracy: 0.5714\n",
      "Epoch 214/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7801 - accuracy: 0.6810 - val_loss: 1.2241 - val_accuracy: 0.6000\n",
      "Epoch 215/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7761 - accuracy: 0.7204 - val_loss: 1.2474 - val_accuracy: 0.6000\n",
      "Epoch 216/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.7644 - accuracy: 0.7025 - val_loss: 1.2135 - val_accuracy: 0.6000\n",
      "Epoch 217/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7652 - accuracy: 0.6810 - val_loss: 1.2321 - val_accuracy: 0.5714\n",
      "Epoch 218/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.7643 - accuracy: 0.6989 - val_loss: 1.2052 - val_accuracy: 0.6286\n",
      "Epoch 219/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7620 - accuracy: 0.6918 - val_loss: 1.2485 - val_accuracy: 0.6000\n",
      "Epoch 220/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7614 - accuracy: 0.7061 - val_loss: 1.2057 - val_accuracy: 0.5571\n",
      "Epoch 221/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.7606 - accuracy: 0.7348 - val_loss: 1.2488 - val_accuracy: 0.5857\n",
      "Epoch 222/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.7615 - accuracy: 0.7061 - val_loss: 1.2347 - val_accuracy: 0.5857\n",
      "Epoch 223/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7578 - accuracy: 0.6882 - val_loss: 1.2308 - val_accuracy: 0.6286\n",
      "Epoch 224/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.7637 - accuracy: 0.7133 - val_loss: 1.2326 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.7433 - accuracy: 0.7240 - val_loss: 1.2181 - val_accuracy: 0.6000\n",
      "Epoch 226/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.7528 - accuracy: 0.7384 - val_loss: 1.2145 - val_accuracy: 0.6000\n",
      "Epoch 227/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7557 - accuracy: 0.7097 - val_loss: 1.2438 - val_accuracy: 0.6000\n",
      "Epoch 228/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.7477 - accuracy: 0.7168 - val_loss: 1.2234 - val_accuracy: 0.5857\n",
      "Epoch 229/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7396 - accuracy: 0.7276 - val_loss: 1.2308 - val_accuracy: 0.5714\n",
      "Epoch 230/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.7435 - accuracy: 0.7025 - val_loss: 1.2662 - val_accuracy: 0.6000\n",
      "Epoch 231/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.7688 - accuracy: 0.6918 - val_loss: 1.2368 - val_accuracy: 0.6286\n",
      "Epoch 232/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.7437 - accuracy: 0.7348 - val_loss: 1.2127 - val_accuracy: 0.5714\n",
      "Epoch 233/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.7665 - accuracy: 0.7097 - val_loss: 1.2287 - val_accuracy: 0.6000\n",
      "Epoch 234/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.7405 - accuracy: 0.7348 - val_loss: 1.2166 - val_accuracy: 0.6286\n",
      "Epoch 235/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.7434 - accuracy: 0.7061 - val_loss: 1.2032 - val_accuracy: 0.5714\n",
      "Epoch 236/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.7302 - accuracy: 0.7061 - val_loss: 1.2181 - val_accuracy: 0.6143\n",
      "Epoch 237/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.7277 - accuracy: 0.7312 - val_loss: 1.2141 - val_accuracy: 0.5857\n",
      "Epoch 238/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.7236 - accuracy: 0.7455 - val_loss: 1.1832 - val_accuracy: 0.5714\n",
      "Epoch 239/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.7254 - accuracy: 0.7312 - val_loss: 1.2693 - val_accuracy: 0.5857\n",
      "Epoch 240/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.7489 - accuracy: 0.6989 - val_loss: 1.2059 - val_accuracy: 0.5714\n",
      "Epoch 241/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.7334 - accuracy: 0.7097 - val_loss: 1.2150 - val_accuracy: 0.5571\n",
      "Epoch 242/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.7508 - accuracy: 0.6989 - val_loss: 1.2380 - val_accuracy: 0.6143\n",
      "Epoch 243/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.7267 - accuracy: 0.7348 - val_loss: 1.1829 - val_accuracy: 0.5714\n",
      "Epoch 244/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.7103 - accuracy: 0.7312 - val_loss: 1.1756 - val_accuracy: 0.6000\n",
      "Epoch 245/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.6997 - accuracy: 0.7419 - val_loss: 1.1897 - val_accuracy: 0.6571\n",
      "Epoch 246/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7203 - accuracy: 0.7240 - val_loss: 1.1845 - val_accuracy: 0.5857\n",
      "Epoch 247/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7164 - accuracy: 0.7312 - val_loss: 1.1782 - val_accuracy: 0.6286\n",
      "Epoch 248/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.7250 - accuracy: 0.7240 - val_loss: 1.2328 - val_accuracy: 0.6429\n",
      "Epoch 249/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.7227 - accuracy: 0.7384 - val_loss: 1.1728 - val_accuracy: 0.6000\n",
      "Epoch 250/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.7040 - accuracy: 0.7025 - val_loss: 1.2078 - val_accuracy: 0.5714\n",
      "Epoch 251/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.7119 - accuracy: 0.7455 - val_loss: 1.2398 - val_accuracy: 0.5429\n",
      "Epoch 252/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7151 - accuracy: 0.7204 - val_loss: 1.1702 - val_accuracy: 0.6286\n",
      "Epoch 253/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7052 - accuracy: 0.6989 - val_loss: 1.2118 - val_accuracy: 0.6429\n",
      "Epoch 254/1000\n",
      "279/279 [==============================] - 0s 69us/step - loss: 0.7182 - accuracy: 0.7348 - val_loss: 1.1939 - val_accuracy: 0.6000\n",
      "Epoch 255/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.6985 - accuracy: 0.7706 - val_loss: 1.2207 - val_accuracy: 0.6000\n",
      "Epoch 256/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.7016 - accuracy: 0.7384 - val_loss: 1.1768 - val_accuracy: 0.5857\n",
      "Epoch 257/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6938 - accuracy: 0.7276 - val_loss: 1.2306 - val_accuracy: 0.6714\n",
      "Epoch 258/1000\n",
      "279/279 [==============================] - 0s 71us/step - loss: 0.6921 - accuracy: 0.7097 - val_loss: 1.1647 - val_accuracy: 0.6000\n",
      "Epoch 259/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6789 - accuracy: 0.7599 - val_loss: 1.1733 - val_accuracy: 0.5857\n",
      "Epoch 260/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.6821 - accuracy: 0.7455 - val_loss: 1.1650 - val_accuracy: 0.6429\n",
      "Epoch 261/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6765 - accuracy: 0.7527 - val_loss: 1.1673 - val_accuracy: 0.6286\n",
      "Epoch 262/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6733 - accuracy: 0.7814 - val_loss: 1.1761 - val_accuracy: 0.5857\n",
      "Epoch 263/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.6698 - accuracy: 0.7491 - val_loss: 1.2052 - val_accuracy: 0.5857\n",
      "Epoch 264/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.6741 - accuracy: 0.7276 - val_loss: 1.1599 - val_accuracy: 0.6714\n",
      "Epoch 265/1000\n",
      "279/279 [==============================] - 0s 95us/step - loss: 0.6667 - accuracy: 0.7527 - val_loss: 1.1748 - val_accuracy: 0.6286\n",
      "Epoch 266/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.6641 - accuracy: 0.7527 - val_loss: 1.1717 - val_accuracy: 0.6429\n",
      "Epoch 267/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6852 - accuracy: 0.7348 - val_loss: 1.2266 - val_accuracy: 0.6143\n",
      "Epoch 268/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6729 - accuracy: 0.7563 - val_loss: 1.1778 - val_accuracy: 0.5857\n",
      "Epoch 269/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.6904 - accuracy: 0.7312 - val_loss: 1.1748 - val_accuracy: 0.6286\n",
      "Epoch 270/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6669 - accuracy: 0.7563 - val_loss: 1.2190 - val_accuracy: 0.6429\n",
      "Epoch 271/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.6753 - accuracy: 0.7491 - val_loss: 1.1710 - val_accuracy: 0.6571\n",
      "Epoch 272/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6620 - accuracy: 0.7706 - val_loss: 1.2013 - val_accuracy: 0.6429\n",
      "Epoch 273/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.6519 - accuracy: 0.7419 - val_loss: 1.2298 - val_accuracy: 0.6857\n",
      "Epoch 274/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6582 - accuracy: 0.7491 - val_loss: 1.1915 - val_accuracy: 0.5714\n",
      "Epoch 275/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6506 - accuracy: 0.7527 - val_loss: 1.1980 - val_accuracy: 0.6429\n",
      "Epoch 276/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6548 - accuracy: 0.7527 - val_loss: 1.1769 - val_accuracy: 0.6286\n",
      "Epoch 277/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.6388 - accuracy: 0.7849 - val_loss: 1.2270 - val_accuracy: 0.6714\n",
      "Epoch 278/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.6505 - accuracy: 0.7706 - val_loss: 1.1473 - val_accuracy: 0.6000\n",
      "Epoch 279/1000\n",
      "279/279 [==============================] - 0s 82us/step - loss: 0.6404 - accuracy: 0.7742 - val_loss: 1.2273 - val_accuracy: 0.6429\n",
      "Epoch 280/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6379 - accuracy: 0.7670 - val_loss: 1.1754 - val_accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 0.6403 - accuracy: 0.7670 - val_loss: 1.1823 - val_accuracy: 0.6714\n",
      "Epoch 282/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.6482 - accuracy: 0.7670 - val_loss: 1.1988 - val_accuracy: 0.6000\n",
      "Epoch 283/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.6332 - accuracy: 0.7849 - val_loss: 1.1741 - val_accuracy: 0.5857\n",
      "Epoch 284/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.6665 - accuracy: 0.7240 - val_loss: 1.2272 - val_accuracy: 0.6714\n",
      "Epoch 285/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6473 - accuracy: 0.7957 - val_loss: 1.1984 - val_accuracy: 0.6714\n",
      "Epoch 286/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.6481 - accuracy: 0.7491 - val_loss: 1.1690 - val_accuracy: 0.6429\n",
      "Epoch 287/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6383 - accuracy: 0.7599 - val_loss: 1.2006 - val_accuracy: 0.6429\n",
      "Epoch 288/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6312 - accuracy: 0.7957 - val_loss: 1.1677 - val_accuracy: 0.6571\n",
      "Epoch 289/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6310 - accuracy: 0.7670 - val_loss: 1.1788 - val_accuracy: 0.6714\n",
      "Epoch 290/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6291 - accuracy: 0.7491 - val_loss: 1.1842 - val_accuracy: 0.6571\n",
      "Epoch 291/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6280 - accuracy: 0.7778 - val_loss: 1.2426 - val_accuracy: 0.6000\n",
      "Epoch 292/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6607 - accuracy: 0.7742 - val_loss: 1.1542 - val_accuracy: 0.6714\n",
      "Epoch 293/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.6592 - accuracy: 0.7419 - val_loss: 1.2549 - val_accuracy: 0.6286\n",
      "Epoch 294/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6385 - accuracy: 0.8065 - val_loss: 1.1391 - val_accuracy: 0.6286\n",
      "Epoch 295/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.6212 - accuracy: 0.7419 - val_loss: 1.2801 - val_accuracy: 0.6857\n",
      "Epoch 296/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6287 - accuracy: 0.7706 - val_loss: 1.1744 - val_accuracy: 0.6571\n",
      "Epoch 297/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6337 - accuracy: 0.7455 - val_loss: 1.2731 - val_accuracy: 0.6714\n",
      "Epoch 298/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.6537 - accuracy: 0.7599 - val_loss: 1.1740 - val_accuracy: 0.6286\n",
      "Epoch 299/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.6040 - accuracy: 0.7814 - val_loss: 1.1918 - val_accuracy: 0.7000\n",
      "Epoch 300/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5988 - accuracy: 0.7742 - val_loss: 1.1832 - val_accuracy: 0.6857\n",
      "Epoch 301/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.5937 - accuracy: 0.7993 - val_loss: 1.1797 - val_accuracy: 0.6571\n",
      "Epoch 302/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.5998 - accuracy: 0.7885 - val_loss: 1.2202 - val_accuracy: 0.6714\n",
      "Epoch 303/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5993 - accuracy: 0.7670 - val_loss: 1.1842 - val_accuracy: 0.6714\n",
      "Epoch 304/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5892 - accuracy: 0.7849 - val_loss: 1.2555 - val_accuracy: 0.7000\n",
      "Epoch 305/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5942 - accuracy: 0.8029 - val_loss: 1.1723 - val_accuracy: 0.7000\n",
      "Epoch 306/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5979 - accuracy: 0.7778 - val_loss: 1.2607 - val_accuracy: 0.6571\n",
      "Epoch 307/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5884 - accuracy: 0.8065 - val_loss: 1.1905 - val_accuracy: 0.6857\n",
      "Epoch 308/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5937 - accuracy: 0.7957 - val_loss: 1.2261 - val_accuracy: 0.7000\n",
      "Epoch 309/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.5835 - accuracy: 0.8136 - val_loss: 1.2238 - val_accuracy: 0.6571\n",
      "Epoch 310/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.5999 - accuracy: 0.7849 - val_loss: 1.2068 - val_accuracy: 0.7000\n",
      "Epoch 311/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5782 - accuracy: 0.7993 - val_loss: 1.2041 - val_accuracy: 0.7000\n",
      "Epoch 312/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.6030 - accuracy: 0.7814 - val_loss: 1.2359 - val_accuracy: 0.6571\n",
      "Epoch 313/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.5801 - accuracy: 0.7957 - val_loss: 1.1499 - val_accuracy: 0.6857\n",
      "Epoch 314/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.5749 - accuracy: 0.7921 - val_loss: 1.2137 - val_accuracy: 0.6429\n",
      "Epoch 315/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.5714 - accuracy: 0.8065 - val_loss: 1.2572 - val_accuracy: 0.6571\n",
      "Epoch 316/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.5621 - accuracy: 0.8065 - val_loss: 1.1628 - val_accuracy: 0.7000\n",
      "Epoch 317/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5632 - accuracy: 0.8280 - val_loss: 1.1956 - val_accuracy: 0.6714\n",
      "Epoch 318/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.5725 - accuracy: 0.7957 - val_loss: 1.2135 - val_accuracy: 0.7143\n",
      "Epoch 319/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.5739 - accuracy: 0.7921 - val_loss: 1.1533 - val_accuracy: 0.6857\n",
      "Epoch 320/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5605 - accuracy: 0.7921 - val_loss: 1.2204 - val_accuracy: 0.6571\n",
      "Epoch 321/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5662 - accuracy: 0.7921 - val_loss: 1.2437 - val_accuracy: 0.6429\n",
      "Epoch 322/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.5685 - accuracy: 0.8029 - val_loss: 1.1994 - val_accuracy: 0.6857\n",
      "Epoch 323/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5620 - accuracy: 0.8280 - val_loss: 1.1979 - val_accuracy: 0.6714\n",
      "Epoch 324/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5771 - accuracy: 0.7885 - val_loss: 1.2782 - val_accuracy: 0.7143\n",
      "Epoch 325/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.5697 - accuracy: 0.8351 - val_loss: 1.1810 - val_accuracy: 0.7143\n",
      "Epoch 326/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.5590 - accuracy: 0.7885 - val_loss: 1.2232 - val_accuracy: 0.7000\n",
      "Epoch 327/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5586 - accuracy: 0.8351 - val_loss: 1.1818 - val_accuracy: 0.6857\n",
      "Epoch 328/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5608 - accuracy: 0.7885 - val_loss: 1.3382 - val_accuracy: 0.6286\n",
      "Epoch 329/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5830 - accuracy: 0.7993 - val_loss: 1.1741 - val_accuracy: 0.6714\n",
      "Epoch 330/1000\n",
      "279/279 [==============================] - 0s 91us/step - loss: 0.5687 - accuracy: 0.8065 - val_loss: 1.2527 - val_accuracy: 0.6714\n",
      "Epoch 331/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5620 - accuracy: 0.7742 - val_loss: 1.2503 - val_accuracy: 0.6857\n",
      "Epoch 332/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5613 - accuracy: 0.8351 - val_loss: 1.1677 - val_accuracy: 0.6571\n",
      "Epoch 333/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.5641 - accuracy: 0.7742 - val_loss: 1.2522 - val_accuracy: 0.7000\n",
      "Epoch 334/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.5518 - accuracy: 0.7993 - val_loss: 1.2321 - val_accuracy: 0.6857\n",
      "Epoch 335/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5517 - accuracy: 0.8351 - val_loss: 1.2343 - val_accuracy: 0.6857\n",
      "Epoch 336/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5723 - accuracy: 0.8100 - val_loss: 1.2711 - val_accuracy: 0.6571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.5564 - accuracy: 0.7993 - val_loss: 1.2216 - val_accuracy: 0.6714\n",
      "Epoch 338/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5526 - accuracy: 0.8100 - val_loss: 1.2228 - val_accuracy: 0.7143\n",
      "Epoch 339/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.5490 - accuracy: 0.8029 - val_loss: 1.2399 - val_accuracy: 0.6857\n",
      "Epoch 340/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5359 - accuracy: 0.7993 - val_loss: 1.1815 - val_accuracy: 0.7143\n",
      "Epoch 341/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.5352 - accuracy: 0.8172 - val_loss: 1.3143 - val_accuracy: 0.6714\n",
      "Epoch 342/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.5380 - accuracy: 0.8244 - val_loss: 1.2107 - val_accuracy: 0.6857\n",
      "Epoch 343/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5363 - accuracy: 0.7849 - val_loss: 1.2578 - val_accuracy: 0.7000\n",
      "Epoch 344/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.5187 - accuracy: 0.8136 - val_loss: 1.2150 - val_accuracy: 0.7143\n",
      "Epoch 345/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5250 - accuracy: 0.8602 - val_loss: 1.2032 - val_accuracy: 0.6857\n",
      "Epoch 346/1000\n",
      "279/279 [==============================] - 0s 101us/step - loss: 0.5241 - accuracy: 0.8244 - val_loss: 1.2089 - val_accuracy: 0.6857\n",
      "Epoch 347/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5191 - accuracy: 0.8495 - val_loss: 1.2013 - val_accuracy: 0.6571\n",
      "Epoch 348/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5117 - accuracy: 0.8351 - val_loss: 1.2285 - val_accuracy: 0.6429\n",
      "Epoch 349/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.5263 - accuracy: 0.7957 - val_loss: 1.2554 - val_accuracy: 0.7429\n",
      "Epoch 350/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5257 - accuracy: 0.8423 - val_loss: 1.2146 - val_accuracy: 0.6429\n",
      "Epoch 351/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5406 - accuracy: 0.7993 - val_loss: 1.2505 - val_accuracy: 0.6857\n",
      "Epoch 352/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.5102 - accuracy: 0.8387 - val_loss: 1.1784 - val_accuracy: 0.7143\n",
      "Epoch 353/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.5460 - accuracy: 0.8100 - val_loss: 1.2996 - val_accuracy: 0.6571\n",
      "Epoch 354/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.5431 - accuracy: 0.7921 - val_loss: 1.2036 - val_accuracy: 0.6857\n",
      "Epoch 355/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.5337 - accuracy: 0.8387 - val_loss: 1.1948 - val_accuracy: 0.6714\n",
      "Epoch 356/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5180 - accuracy: 0.8280 - val_loss: 1.2351 - val_accuracy: 0.6857\n",
      "Epoch 357/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.5657 - accuracy: 0.7706 - val_loss: 1.3653 - val_accuracy: 0.6286\n",
      "Epoch 358/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5440 - accuracy: 0.7885 - val_loss: 1.1981 - val_accuracy: 0.6714\n",
      "Epoch 359/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.5291 - accuracy: 0.7885 - val_loss: 1.2911 - val_accuracy: 0.7000\n",
      "Epoch 360/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.5249 - accuracy: 0.7993 - val_loss: 1.1764 - val_accuracy: 0.6571\n",
      "Epoch 361/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4905 - accuracy: 0.8530 - val_loss: 1.2342 - val_accuracy: 0.7000\n",
      "Epoch 362/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.4938 - accuracy: 0.8530 - val_loss: 1.1836 - val_accuracy: 0.7000\n",
      "Epoch 363/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.4826 - accuracy: 0.8351 - val_loss: 1.2695 - val_accuracy: 0.7143\n",
      "Epoch 364/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.4933 - accuracy: 0.8566 - val_loss: 1.1647 - val_accuracy: 0.7143\n",
      "Epoch 365/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5056 - accuracy: 0.8387 - val_loss: 1.2987 - val_accuracy: 0.6286\n",
      "Epoch 366/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.5045 - accuracy: 0.8280 - val_loss: 1.2122 - val_accuracy: 0.7571\n",
      "Epoch 367/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.4897 - accuracy: 0.8602 - val_loss: 1.2080 - val_accuracy: 0.7143\n",
      "Epoch 368/1000\n",
      "279/279 [==============================] - 0s 69us/step - loss: 0.4846 - accuracy: 0.8280 - val_loss: 1.2826 - val_accuracy: 0.7000\n",
      "Epoch 369/1000\n",
      "279/279 [==============================] - 0s 57us/step - loss: 0.4917 - accuracy: 0.8495 - val_loss: 1.2670 - val_accuracy: 0.7143\n",
      "Epoch 370/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4824 - accuracy: 0.8423 - val_loss: 1.1982 - val_accuracy: 0.7000\n",
      "Epoch 371/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.4860 - accuracy: 0.8423 - val_loss: 1.2892 - val_accuracy: 0.6714\n",
      "Epoch 372/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.4997 - accuracy: 0.8387 - val_loss: 1.2444 - val_accuracy: 0.6714\n",
      "Epoch 373/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4906 - accuracy: 0.8172 - val_loss: 1.2993 - val_accuracy: 0.6857\n",
      "Epoch 374/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.5221 - accuracy: 0.8208 - val_loss: 1.2083 - val_accuracy: 0.6857\n",
      "Epoch 375/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.4865 - accuracy: 0.8208 - val_loss: 1.2852 - val_accuracy: 0.6857\n",
      "Epoch 376/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.4941 - accuracy: 0.8315 - val_loss: 1.2417 - val_accuracy: 0.7000\n",
      "Epoch 377/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.4783 - accuracy: 0.8208 - val_loss: 1.2446 - val_accuracy: 0.7000\n",
      "Epoch 378/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.4829 - accuracy: 0.8136 - val_loss: 1.2684 - val_accuracy: 0.6571\n",
      "Epoch 379/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 0.4842 - accuracy: 0.8674 - val_loss: 1.1870 - val_accuracy: 0.6857\n",
      "Epoch 380/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.5123 - accuracy: 0.8280 - val_loss: 1.2416 - val_accuracy: 0.6857\n",
      "Epoch 381/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.4926 - accuracy: 0.8100 - val_loss: 1.2772 - val_accuracy: 0.7000\n",
      "Epoch 382/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 0.4893 - accuracy: 0.8387 - val_loss: 1.1897 - val_accuracy: 0.7286\n",
      "Epoch 383/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4686 - accuracy: 0.8638 - val_loss: 1.2367 - val_accuracy: 0.7143\n",
      "Epoch 384/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.4664 - accuracy: 0.8602 - val_loss: 1.2402 - val_accuracy: 0.7429\n",
      "Epoch 385/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.4561 - accuracy: 0.8566 - val_loss: 1.2346 - val_accuracy: 0.6857\n",
      "Epoch 386/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.4722 - accuracy: 0.8280 - val_loss: 1.2560 - val_accuracy: 0.7286\n",
      "Epoch 387/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.4613 - accuracy: 0.8602 - val_loss: 1.1891 - val_accuracy: 0.6857\n",
      "Epoch 388/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.4525 - accuracy: 0.8566 - val_loss: 1.2266 - val_accuracy: 0.7429\n",
      "Epoch 389/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.4500 - accuracy: 0.8459 - val_loss: 1.2507 - val_accuracy: 0.7000\n",
      "Epoch 390/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.4637 - accuracy: 0.8853 - val_loss: 1.2292 - val_accuracy: 0.7000\n",
      "Epoch 391/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.4523 - accuracy: 0.8495 - val_loss: 1.2451 - val_accuracy: 0.7000\n",
      "Epoch 392/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4518 - accuracy: 0.8351 - val_loss: 1.1964 - val_accuracy: 0.7429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "279/279 [==============================] - 0s 71us/step - loss: 0.4474 - accuracy: 0.8674 - val_loss: 1.2905 - val_accuracy: 0.7000\n",
      "Epoch 394/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.4710 - accuracy: 0.8459 - val_loss: 1.2417 - val_accuracy: 0.7286\n",
      "Epoch 395/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.4536 - accuracy: 0.8638 - val_loss: 1.2045 - val_accuracy: 0.7571\n",
      "Epoch 396/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.4383 - accuracy: 0.8566 - val_loss: 1.2878 - val_accuracy: 0.7000\n",
      "Epoch 397/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.4471 - accuracy: 0.8746 - val_loss: 1.2566 - val_accuracy: 0.7429\n",
      "Epoch 398/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.4356 - accuracy: 0.8746 - val_loss: 1.2202 - val_accuracy: 0.7571\n",
      "Epoch 399/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.4461 - accuracy: 0.8459 - val_loss: 1.3068 - val_accuracy: 0.6571\n",
      "Epoch 400/1000\n",
      "279/279 [==============================] - 0s 95us/step - loss: 0.4444 - accuracy: 0.8495 - val_loss: 1.2525 - val_accuracy: 0.7286\n",
      "Epoch 401/1000\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.87 - 0s 72us/step - loss: 0.4448 - accuracy: 0.8530 - val_loss: 1.2850 - val_accuracy: 0.7429\n",
      "Epoch 402/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4465 - accuracy: 0.8602 - val_loss: 1.2530 - val_accuracy: 0.7000\n",
      "Epoch 403/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.4394 - accuracy: 0.8781 - val_loss: 1.2652 - val_accuracy: 0.7571\n",
      "Epoch 404/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4239 - accuracy: 0.8530 - val_loss: 1.2777 - val_accuracy: 0.7286\n",
      "Epoch 405/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4206 - accuracy: 0.8530 - val_loss: 1.2995 - val_accuracy: 0.7286\n",
      "Epoch 406/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.4319 - accuracy: 0.8853 - val_loss: 1.2185 - val_accuracy: 0.7000\n",
      "Epoch 407/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.4380 - accuracy: 0.8387 - val_loss: 1.2282 - val_accuracy: 0.7286\n",
      "Epoch 408/1000\n",
      "279/279 [==============================] - 0s 50us/step - loss: 0.4373 - accuracy: 0.8674 - val_loss: 1.3230 - val_accuracy: 0.6857\n",
      "Epoch 409/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4512 - accuracy: 0.8387 - val_loss: 1.2489 - val_accuracy: 0.7429\n",
      "Epoch 410/1000\n",
      "279/279 [==============================] - 0s 133us/step - loss: 0.4464 - accuracy: 0.8566 - val_loss: 1.2956 - val_accuracy: 0.6571\n",
      "Epoch 411/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.4313 - accuracy: 0.8315 - val_loss: 1.2525 - val_accuracy: 0.7143\n",
      "Epoch 412/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.4234 - accuracy: 0.8530 - val_loss: 1.2600 - val_accuracy: 0.7143\n",
      "Epoch 413/1000\n",
      "279/279 [==============================] - 0s 97us/step - loss: 0.4232 - accuracy: 0.8710 - val_loss: 1.2439 - val_accuracy: 0.6857\n",
      "Epoch 414/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.4145 - accuracy: 0.8853 - val_loss: 1.2747 - val_accuracy: 0.7286\n",
      "Epoch 415/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.4257 - accuracy: 0.8710 - val_loss: 1.2653 - val_accuracy: 0.7286\n",
      "Epoch 416/1000\n",
      "279/279 [==============================] - 0s 99us/step - loss: 0.4326 - accuracy: 0.8530 - val_loss: 1.2888 - val_accuracy: 0.7143\n",
      "Epoch 417/1000\n",
      "279/279 [==============================] - 0s 93us/step - loss: 0.4456 - accuracy: 0.8423 - val_loss: 1.2751 - val_accuracy: 0.7000\n",
      "Epoch 418/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.4619 - accuracy: 0.8315 - val_loss: 1.4492 - val_accuracy: 0.6143\n",
      "Epoch 419/1000\n",
      "279/279 [==============================] - 0s 101us/step - loss: 0.5095 - accuracy: 0.8172 - val_loss: 1.2474 - val_accuracy: 0.7286\n",
      "Epoch 420/1000\n",
      "279/279 [==============================] - 0s 155us/step - loss: 0.4508 - accuracy: 0.8459 - val_loss: 1.3182 - val_accuracy: 0.6714\n",
      "Epoch 421/1000\n",
      "279/279 [==============================] - 0s 111us/step - loss: 0.4327 - accuracy: 0.8602 - val_loss: 1.2698 - val_accuracy: 0.7143\n",
      "Epoch 422/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.4260 - accuracy: 0.8710 - val_loss: 1.2912 - val_accuracy: 0.7429\n",
      "Epoch 423/1000\n",
      "279/279 [==============================] - 0s 97us/step - loss: 0.4122 - accuracy: 0.8602 - val_loss: 1.2481 - val_accuracy: 0.7286\n",
      "Epoch 424/1000\n",
      "279/279 [==============================] - 0s 99us/step - loss: 0.4188 - accuracy: 0.8459 - val_loss: 1.2813 - val_accuracy: 0.6714\n",
      "Epoch 425/1000\n",
      "279/279 [==============================] - 0s 111us/step - loss: 0.4093 - accuracy: 0.8459 - val_loss: 1.2605 - val_accuracy: 0.7000\n",
      "Epoch 426/1000\n",
      "279/279 [==============================] - 0s 101us/step - loss: 0.4119 - accuracy: 0.8638 - val_loss: 1.2320 - val_accuracy: 0.7571\n",
      "Epoch 427/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.4225 - accuracy: 0.8602 - val_loss: 1.3211 - val_accuracy: 0.6429\n",
      "Epoch 428/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.4194 - accuracy: 0.8423 - val_loss: 1.3185 - val_accuracy: 0.6857\n",
      "Epoch 429/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.4122 - accuracy: 0.8602 - val_loss: 1.2763 - val_accuracy: 0.7143\n",
      "Epoch 430/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.4237 - accuracy: 0.8459 - val_loss: 1.2912 - val_accuracy: 0.6143\n",
      "Epoch 431/1000\n",
      "279/279 [==============================] - 0s 104us/step - loss: 0.4475 - accuracy: 0.8315 - val_loss: 1.3527 - val_accuracy: 0.7143\n",
      "Epoch 432/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.4095 - accuracy: 0.8602 - val_loss: 1.2211 - val_accuracy: 0.7286\n",
      "Epoch 433/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.4072 - accuracy: 0.8423 - val_loss: 1.3062 - val_accuracy: 0.6714\n",
      "Epoch 434/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.4014 - accuracy: 0.8746 - val_loss: 1.2589 - val_accuracy: 0.7286\n",
      "Epoch 435/1000\n",
      "279/279 [==============================] - 0s 111us/step - loss: 0.4067 - accuracy: 0.8459 - val_loss: 1.3257 - val_accuracy: 0.7143\n",
      "Epoch 436/1000\n",
      "279/279 [==============================] - 0s 97us/step - loss: 0.4021 - accuracy: 0.8925 - val_loss: 1.2614 - val_accuracy: 0.7000\n",
      "Epoch 437/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.4028 - accuracy: 0.8495 - val_loss: 1.3544 - val_accuracy: 0.7143\n",
      "Epoch 438/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.4140 - accuracy: 0.8566 - val_loss: 1.3024 - val_accuracy: 0.7143\n",
      "Epoch 439/1000\n",
      "279/279 [==============================] - 0s 92us/step - loss: 0.4052 - accuracy: 0.8674 - val_loss: 1.2216 - val_accuracy: 0.7286\n",
      "Epoch 440/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.3920 - accuracy: 0.8674 - val_loss: 1.3459 - val_accuracy: 0.7143\n",
      "Epoch 441/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.3869 - accuracy: 0.8961 - val_loss: 1.2610 - val_accuracy: 0.7429\n",
      "Epoch 442/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.3979 - accuracy: 0.8638 - val_loss: 1.2061 - val_accuracy: 0.7286\n",
      "Epoch 443/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.4093 - accuracy: 0.8638 - val_loss: 1.2596 - val_accuracy: 0.7000\n",
      "Epoch 444/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.3917 - accuracy: 0.8530 - val_loss: 1.3770 - val_accuracy: 0.7143\n",
      "Epoch 445/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.4220 - accuracy: 0.8710 - val_loss: 1.2552 - val_accuracy: 0.7143\n",
      "Epoch 446/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3936 - accuracy: 0.8817 - val_loss: 1.3548 - val_accuracy: 0.7286\n",
      "Epoch 447/1000\n",
      "279/279 [==============================] - 0s 106us/step - loss: 0.4097 - accuracy: 0.8674 - val_loss: 1.2422 - val_accuracy: 0.7571\n",
      "Epoch 448/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 0s 104us/step - loss: 0.3827 - accuracy: 0.8817 - val_loss: 1.2873 - val_accuracy: 0.7143\n",
      "Epoch 449/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.3999 - accuracy: 0.8530 - val_loss: 1.2910 - val_accuracy: 0.7429\n",
      "Epoch 450/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3942 - accuracy: 0.8602 - val_loss: 1.2650 - val_accuracy: 0.7143\n",
      "Epoch 451/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3845 - accuracy: 0.8638 - val_loss: 1.3422 - val_accuracy: 0.7429\n",
      "Epoch 452/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3885 - accuracy: 0.8746 - val_loss: 1.2198 - val_accuracy: 0.7714\n",
      "Epoch 453/1000\n",
      "279/279 [==============================] - 0s 104us/step - loss: 0.4007 - accuracy: 0.8674 - val_loss: 1.3118 - val_accuracy: 0.7714\n",
      "Epoch 454/1000\n",
      "279/279 [==============================] - 0s 93us/step - loss: 0.4257 - accuracy: 0.8351 - val_loss: 1.4346 - val_accuracy: 0.7000\n",
      "Epoch 455/1000\n",
      "279/279 [==============================] - 0s 144us/step - loss: 0.3804 - accuracy: 0.8853 - val_loss: 1.2731 - val_accuracy: 0.7571\n",
      "Epoch 456/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.3806 - accuracy: 0.8853 - val_loss: 1.3372 - val_accuracy: 0.6714\n",
      "Epoch 457/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3716 - accuracy: 0.8817 - val_loss: 1.3167 - val_accuracy: 0.6857\n",
      "Epoch 458/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.3700 - accuracy: 0.8781 - val_loss: 1.2842 - val_accuracy: 0.7429\n",
      "Epoch 459/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.3823 - accuracy: 0.8746 - val_loss: 1.2412 - val_accuracy: 0.7571\n",
      "Epoch 460/1000\n",
      "279/279 [==============================] - 0s 58us/step - loss: 0.3678 - accuracy: 0.8710 - val_loss: 1.3463 - val_accuracy: 0.7286\n",
      "Epoch 461/1000\n",
      "279/279 [==============================] - 0s 58us/step - loss: 0.3818 - accuracy: 0.8710 - val_loss: 1.3056 - val_accuracy: 0.7429\n",
      "Epoch 462/1000\n",
      "279/279 [==============================] - 0s 123us/step - loss: 0.3975 - accuracy: 0.8602 - val_loss: 1.3657 - val_accuracy: 0.6000\n",
      "Epoch 463/1000\n",
      "279/279 [==============================] - 0s 62us/step - loss: 0.4203 - accuracy: 0.8602 - val_loss: 1.3792 - val_accuracy: 0.6857\n",
      "Epoch 464/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.3746 - accuracy: 0.8961 - val_loss: 1.2464 - val_accuracy: 0.7286\n",
      "Epoch 465/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.3720 - accuracy: 0.8746 - val_loss: 1.3408 - val_accuracy: 0.7571\n",
      "Epoch 466/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3609 - accuracy: 0.8996 - val_loss: 1.2775 - val_accuracy: 0.7286\n",
      "Epoch 467/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.3711 - accuracy: 0.8889 - val_loss: 1.2802 - val_accuracy: 0.7286\n",
      "Epoch 468/1000\n",
      "279/279 [==============================] - 0s 97us/step - loss: 0.3739 - accuracy: 0.8961 - val_loss: 1.3339 - val_accuracy: 0.7286\n",
      "Epoch 469/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.3687 - accuracy: 0.8817 - val_loss: 1.2679 - val_accuracy: 0.7429\n",
      "Epoch 470/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.3626 - accuracy: 0.8925 - val_loss: 1.2202 - val_accuracy: 0.8000\n",
      "Epoch 471/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3828 - accuracy: 0.8638 - val_loss: 1.4280 - val_accuracy: 0.7143\n",
      "Epoch 472/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3929 - accuracy: 0.8602 - val_loss: 1.3412 - val_accuracy: 0.7286\n",
      "Epoch 473/1000\n",
      "279/279 [==============================] - 0s 69us/step - loss: 0.3710 - accuracy: 0.8817 - val_loss: 1.2434 - val_accuracy: 0.7857\n",
      "Epoch 474/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3626 - accuracy: 0.8925 - val_loss: 1.4114 - val_accuracy: 0.6857\n",
      "Epoch 475/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3529 - accuracy: 0.8925 - val_loss: 1.2739 - val_accuracy: 0.7714\n",
      "Epoch 476/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3888 - accuracy: 0.8710 - val_loss: 1.3304 - val_accuracy: 0.6714\n",
      "Epoch 477/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.3840 - accuracy: 0.8566 - val_loss: 1.3751 - val_accuracy: 0.7143\n",
      "Epoch 478/1000\n",
      "279/279 [==============================] - 0s 71us/step - loss: 0.3956 - accuracy: 0.8746 - val_loss: 1.3423 - val_accuracy: 0.7286\n",
      "Epoch 479/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3985 - accuracy: 0.8459 - val_loss: 1.2790 - val_accuracy: 0.7429\n",
      "Epoch 480/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3867 - accuracy: 0.8530 - val_loss: 1.3034 - val_accuracy: 0.6857\n",
      "Epoch 481/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.3641 - accuracy: 0.8710 - val_loss: 1.3740 - val_accuracy: 0.7571\n",
      "Epoch 482/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.3632 - accuracy: 0.8817 - val_loss: 1.2748 - val_accuracy: 0.7143\n",
      "Epoch 483/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3845 - accuracy: 0.8566 - val_loss: 1.3781 - val_accuracy: 0.6857\n",
      "Epoch 484/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3759 - accuracy: 0.8781 - val_loss: 1.2812 - val_accuracy: 0.7714\n",
      "Epoch 485/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3567 - accuracy: 0.8889 - val_loss: 1.2789 - val_accuracy: 0.7143\n",
      "Epoch 486/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.3551 - accuracy: 0.8889 - val_loss: 1.2937 - val_accuracy: 0.7286\n",
      "Epoch 487/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3426 - accuracy: 0.8889 - val_loss: 1.3714 - val_accuracy: 0.7286\n",
      "Epoch 488/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3531 - accuracy: 0.8961 - val_loss: 1.2672 - val_accuracy: 0.7000\n",
      "Epoch 489/1000\n",
      "279/279 [==============================] - 0s 50us/step - loss: 0.3423 - accuracy: 0.8746 - val_loss: 1.2825 - val_accuracy: 0.7714\n",
      "Epoch 490/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.3357 - accuracy: 0.9104 - val_loss: 1.3083 - val_accuracy: 0.7571\n",
      "Epoch 491/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3643 - accuracy: 0.8602 - val_loss: 1.3733 - val_accuracy: 0.7000\n",
      "Epoch 492/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3462 - accuracy: 0.8996 - val_loss: 1.2646 - val_accuracy: 0.7429\n",
      "Epoch 493/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.3613 - accuracy: 0.8746 - val_loss: 1.2778 - val_accuracy: 0.7286\n",
      "Epoch 494/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.3503 - accuracy: 0.8746 - val_loss: 1.3484 - val_accuracy: 0.7000\n",
      "Epoch 495/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.3386 - accuracy: 0.9140 - val_loss: 1.2228 - val_accuracy: 0.7714\n",
      "Epoch 496/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3342 - accuracy: 0.8961 - val_loss: 1.3497 - val_accuracy: 0.7143\n",
      "Epoch 497/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.3405 - accuracy: 0.8853 - val_loss: 1.2982 - val_accuracy: 0.7571\n",
      "Epoch 498/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 0.3282 - accuracy: 0.8996 - val_loss: 1.2797 - val_accuracy: 0.7143\n",
      "Epoch 499/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3245 - accuracy: 0.9104 - val_loss: 1.3277 - val_accuracy: 0.7286\n",
      "Epoch 500/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3301 - accuracy: 0.9140 - val_loss: 1.3415 - val_accuracy: 0.7143\n",
      "Epoch 501/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.3512 - accuracy: 0.8710 - val_loss: 1.3327 - val_accuracy: 0.7000\n",
      "Epoch 502/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3384 - accuracy: 0.9032 - val_loss: 1.2359 - val_accuracy: 0.7857\n",
      "Epoch 503/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3344 - accuracy: 0.8817 - val_loss: 1.2758 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3325 - accuracy: 0.8925 - val_loss: 1.3253 - val_accuracy: 0.7143\n",
      "Epoch 505/1000\n",
      "279/279 [==============================] - 0s 73us/step - loss: 0.3204 - accuracy: 0.9068 - val_loss: 1.2842 - val_accuracy: 0.8000\n",
      "Epoch 506/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.3288 - accuracy: 0.9032 - val_loss: 1.2527 - val_accuracy: 0.7714\n",
      "Epoch 507/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.3369 - accuracy: 0.8889 - val_loss: 1.3689 - val_accuracy: 0.7286\n",
      "Epoch 508/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.3403 - accuracy: 0.8961 - val_loss: 1.3305 - val_accuracy: 0.7143\n",
      "Epoch 509/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3388 - accuracy: 0.8925 - val_loss: 1.2843 - val_accuracy: 0.7857\n",
      "Epoch 510/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.3438 - accuracy: 0.9032 - val_loss: 1.3280 - val_accuracy: 0.7286\n",
      "Epoch 511/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.3304 - accuracy: 0.9176 - val_loss: 1.2888 - val_accuracy: 0.7000\n",
      "Epoch 512/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.3405 - accuracy: 0.8710 - val_loss: 1.3826 - val_accuracy: 0.7429\n",
      "Epoch 513/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.3302 - accuracy: 0.8996 - val_loss: 1.2249 - val_accuracy: 0.7429\n",
      "Epoch 514/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.3359 - accuracy: 0.8996 - val_loss: 1.3667 - val_accuracy: 0.7714\n",
      "Epoch 515/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.3331 - accuracy: 0.8853 - val_loss: 1.2983 - val_accuracy: 0.7143\n",
      "Epoch 516/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3252 - accuracy: 0.8889 - val_loss: 1.4100 - val_accuracy: 0.7000\n",
      "Epoch 517/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3405 - accuracy: 0.8710 - val_loss: 1.3166 - val_accuracy: 0.7714\n",
      "Epoch 518/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3722 - accuracy: 0.8459 - val_loss: 1.3405 - val_accuracy: 0.7000\n",
      "Epoch 519/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.3391 - accuracy: 0.8710 - val_loss: 1.3386 - val_accuracy: 0.7000\n",
      "Epoch 520/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3420 - accuracy: 0.8746 - val_loss: 1.2742 - val_accuracy: 0.7857\n",
      "Epoch 521/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.3309 - accuracy: 0.8961 - val_loss: 1.3021 - val_accuracy: 0.7143\n",
      "Epoch 522/1000\n",
      "279/279 [==============================] - 0s 78us/step - loss: 0.3136 - accuracy: 0.8961 - val_loss: 1.3154 - val_accuracy: 0.7429\n",
      "Epoch 523/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.3192 - accuracy: 0.8996 - val_loss: 1.3137 - val_accuracy: 0.7571\n",
      "Epoch 524/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3289 - accuracy: 0.8781 - val_loss: 1.2791 - val_accuracy: 0.7714\n",
      "Epoch 525/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3199 - accuracy: 0.8925 - val_loss: 1.3006 - val_accuracy: 0.7429\n",
      "Epoch 526/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3030 - accuracy: 0.9283 - val_loss: 1.3026 - val_accuracy: 0.7571\n",
      "Epoch 527/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.3053 - accuracy: 0.8996 - val_loss: 1.3144 - val_accuracy: 0.7571\n",
      "Epoch 528/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3077 - accuracy: 0.8996 - val_loss: 1.2659 - val_accuracy: 0.7714\n",
      "Epoch 529/1000\n",
      "279/279 [==============================] - 0s 73us/step - loss: 0.3128 - accuracy: 0.8996 - val_loss: 1.4226 - val_accuracy: 0.7000\n",
      "Epoch 530/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3161 - accuracy: 0.8996 - val_loss: 1.2294 - val_accuracy: 0.8143\n",
      "Epoch 531/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.3060 - accuracy: 0.9176 - val_loss: 1.3331 - val_accuracy: 0.7143\n",
      "Epoch 532/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3238 - accuracy: 0.9104 - val_loss: 1.3117 - val_accuracy: 0.7000\n",
      "Epoch 533/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3221 - accuracy: 0.8961 - val_loss: 1.2866 - val_accuracy: 0.7714\n",
      "Epoch 534/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2946 - accuracy: 0.9176 - val_loss: 1.3349 - val_accuracy: 0.7429\n",
      "Epoch 535/1000\n",
      "279/279 [==============================] - 0s 104us/step - loss: 0.3013 - accuracy: 0.9211 - val_loss: 1.2775 - val_accuracy: 0.7857\n",
      "Epoch 536/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3047 - accuracy: 0.9247 - val_loss: 1.3857 - val_accuracy: 0.6857\n",
      "Epoch 537/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.3153 - accuracy: 0.8925 - val_loss: 1.3292 - val_accuracy: 0.7714\n",
      "Epoch 538/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3084 - accuracy: 0.9032 - val_loss: 1.3586 - val_accuracy: 0.7143\n",
      "Epoch 539/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3240 - accuracy: 0.8961 - val_loss: 1.3495 - val_accuracy: 0.7714\n",
      "Epoch 540/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3295 - accuracy: 0.8889 - val_loss: 1.2796 - val_accuracy: 0.7143\n",
      "Epoch 541/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3049 - accuracy: 0.8996 - val_loss: 1.3116 - val_accuracy: 0.8000\n",
      "Epoch 542/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3051 - accuracy: 0.9211 - val_loss: 1.2931 - val_accuracy: 0.7857\n",
      "Epoch 543/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.3003 - accuracy: 0.8961 - val_loss: 1.3137 - val_accuracy: 0.7857\n",
      "Epoch 544/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.3018 - accuracy: 0.8961 - val_loss: 1.3854 - val_accuracy: 0.7000\n",
      "Epoch 545/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2936 - accuracy: 0.8961 - val_loss: 1.3316 - val_accuracy: 0.7000\n",
      "Epoch 546/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3053 - accuracy: 0.8996 - val_loss: 1.3462 - val_accuracy: 0.7286\n",
      "Epoch 547/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3012 - accuracy: 0.8961 - val_loss: 1.2603 - val_accuracy: 0.7857\n",
      "Epoch 548/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2991 - accuracy: 0.9104 - val_loss: 1.3275 - val_accuracy: 0.7571\n",
      "Epoch 549/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2961 - accuracy: 0.9068 - val_loss: 1.2987 - val_accuracy: 0.8000\n",
      "Epoch 550/1000\n",
      "279/279 [==============================] - 0s 93us/step - loss: 0.2996 - accuracy: 0.9211 - val_loss: 1.3839 - val_accuracy: 0.6857\n",
      "Epoch 551/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.3124 - accuracy: 0.8853 - val_loss: 1.3725 - val_accuracy: 0.7000\n",
      "Epoch 552/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.3014 - accuracy: 0.8925 - val_loss: 1.2806 - val_accuracy: 0.7857\n",
      "Epoch 553/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.2885 - accuracy: 0.9247 - val_loss: 1.3230 - val_accuracy: 0.7571\n",
      "Epoch 554/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 0.2962 - accuracy: 0.8996 - val_loss: 1.3666 - val_accuracy: 0.7143\n",
      "Epoch 555/1000\n",
      "279/279 [==============================] - 0s 82us/step - loss: 0.2870 - accuracy: 0.9427 - val_loss: 1.3236 - val_accuracy: 0.7857\n",
      "Epoch 556/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2927 - accuracy: 0.8996 - val_loss: 1.3364 - val_accuracy: 0.7143\n",
      "Epoch 557/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2906 - accuracy: 0.9032 - val_loss: 1.2705 - val_accuracy: 0.8000\n",
      "Epoch 558/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2831 - accuracy: 0.9211 - val_loss: 1.3493 - val_accuracy: 0.7143\n",
      "Epoch 559/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.3008 - accuracy: 0.9032 - val_loss: 1.3957 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.3105 - accuracy: 0.8817 - val_loss: 1.2882 - val_accuracy: 0.8429\n",
      "Epoch 561/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.3014 - accuracy: 0.9176 - val_loss: 1.2856 - val_accuracy: 0.7857\n",
      "Epoch 562/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.3040 - accuracy: 0.8853 - val_loss: 1.3622 - val_accuracy: 0.7000\n",
      "Epoch 563/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2992 - accuracy: 0.9104 - val_loss: 1.3788 - val_accuracy: 0.7571\n",
      "Epoch 564/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2851 - accuracy: 0.9211 - val_loss: 1.3220 - val_accuracy: 0.8000\n",
      "Epoch 565/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.3034 - accuracy: 0.9032 - val_loss: 1.3175 - val_accuracy: 0.8000\n",
      "Epoch 566/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.3207 - accuracy: 0.8889 - val_loss: 1.3228 - val_accuracy: 0.6857\n",
      "Epoch 567/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.3083 - accuracy: 0.8961 - val_loss: 1.3376 - val_accuracy: 0.7714\n",
      "Epoch 568/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2960 - accuracy: 0.9104 - val_loss: 1.2935 - val_accuracy: 0.7857\n",
      "Epoch 569/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2802 - accuracy: 0.9068 - val_loss: 1.2694 - val_accuracy: 0.7571\n",
      "Epoch 570/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2878 - accuracy: 0.9032 - val_loss: 1.4004 - val_accuracy: 0.7286\n",
      "Epoch 571/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.3051 - accuracy: 0.9068 - val_loss: 1.2982 - val_accuracy: 0.7857\n",
      "Epoch 572/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.2862 - accuracy: 0.9176 - val_loss: 1.2973 - val_accuracy: 0.8286\n",
      "Epoch 573/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.2877 - accuracy: 0.9032 - val_loss: 1.3521 - val_accuracy: 0.7429\n",
      "Epoch 574/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2971 - accuracy: 0.8889 - val_loss: 1.3136 - val_accuracy: 0.8143\n",
      "Epoch 575/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2798 - accuracy: 0.9283 - val_loss: 1.3818 - val_accuracy: 0.7286\n",
      "Epoch 576/1000\n",
      "279/279 [==============================] - 0s 80us/step - loss: 0.2993 - accuracy: 0.9068 - val_loss: 1.3671 - val_accuracy: 0.7429\n",
      "Epoch 577/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2800 - accuracy: 0.9032 - val_loss: 1.3703 - val_accuracy: 0.7000\n",
      "Epoch 578/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.3069 - accuracy: 0.9032 - val_loss: 1.2724 - val_accuracy: 0.8286\n",
      "Epoch 579/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.2953 - accuracy: 0.8996 - val_loss: 1.3157 - val_accuracy: 0.7571\n",
      "Epoch 580/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.2921 - accuracy: 0.8996 - val_loss: 1.3774 - val_accuracy: 0.7286\n",
      "Epoch 581/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2863 - accuracy: 0.9032 - val_loss: 1.3115 - val_accuracy: 0.7857\n",
      "Epoch 582/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2728 - accuracy: 0.9104 - val_loss: 1.3168 - val_accuracy: 0.7429\n",
      "Epoch 583/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2771 - accuracy: 0.9176 - val_loss: 1.3012 - val_accuracy: 0.8143\n",
      "Epoch 584/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2738 - accuracy: 0.9176 - val_loss: 1.2863 - val_accuracy: 0.8000\n",
      "Epoch 585/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2823 - accuracy: 0.9104 - val_loss: 1.3328 - val_accuracy: 0.7429\n",
      "Epoch 586/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2629 - accuracy: 0.9176 - val_loss: 1.3193 - val_accuracy: 0.7857\n",
      "Epoch 587/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.2621 - accuracy: 0.9176 - val_loss: 1.3516 - val_accuracy: 0.7429\n",
      "Epoch 588/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.2672 - accuracy: 0.9355 - val_loss: 1.2971 - val_accuracy: 0.8429\n",
      "Epoch 589/1000\n",
      "279/279 [==============================] - 0s 89us/step - loss: 0.2636 - accuracy: 0.9211 - val_loss: 1.3573 - val_accuracy: 0.7286\n",
      "Epoch 590/1000\n",
      "279/279 [==============================] - 0s 104us/step - loss: 0.2648 - accuracy: 0.9032 - val_loss: 1.2959 - val_accuracy: 0.8143\n",
      "Epoch 591/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.2766 - accuracy: 0.9068 - val_loss: 1.2801 - val_accuracy: 0.7571\n",
      "Epoch 592/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.2697 - accuracy: 0.9247 - val_loss: 1.3283 - val_accuracy: 0.7857\n",
      "Epoch 593/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.2830 - accuracy: 0.9032 - val_loss: 1.3862 - val_accuracy: 0.7857\n",
      "Epoch 594/1000\n",
      "279/279 [==============================] - 0s 104us/step - loss: 0.2728 - accuracy: 0.9247 - val_loss: 1.2847 - val_accuracy: 0.7857\n",
      "Epoch 595/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2605 - accuracy: 0.9211 - val_loss: 1.3220 - val_accuracy: 0.8143\n",
      "Epoch 596/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.2596 - accuracy: 0.9176 - val_loss: 1.3333 - val_accuracy: 0.8143\n",
      "Epoch 597/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.2664 - accuracy: 0.9104 - val_loss: 1.3497 - val_accuracy: 0.7714\n",
      "Epoch 598/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2546 - accuracy: 0.9247 - val_loss: 1.3486 - val_accuracy: 0.7857\n",
      "Epoch 599/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2722 - accuracy: 0.9140 - val_loss: 1.3491 - val_accuracy: 0.7857\n",
      "Epoch 600/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2829 - accuracy: 0.9068 - val_loss: 1.4600 - val_accuracy: 0.6714\n",
      "Epoch 601/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2903 - accuracy: 0.8889 - val_loss: 1.3314 - val_accuracy: 0.7429\n",
      "Epoch 602/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.2790 - accuracy: 0.8996 - val_loss: 1.3188 - val_accuracy: 0.8143\n",
      "Epoch 603/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2565 - accuracy: 0.9247 - val_loss: 1.2935 - val_accuracy: 0.8143\n",
      "Epoch 604/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2634 - accuracy: 0.9104 - val_loss: 1.3615 - val_accuracy: 0.7714\n",
      "Epoch 605/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2589 - accuracy: 0.9104 - val_loss: 1.4264 - val_accuracy: 0.7143\n",
      "Epoch 606/1000\n",
      "279/279 [==============================] - 0s 73us/step - loss: 0.2587 - accuracy: 0.9247 - val_loss: 1.3003 - val_accuracy: 0.7714\n",
      "Epoch 607/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2645 - accuracy: 0.9211 - val_loss: 1.3744 - val_accuracy: 0.7286\n",
      "Epoch 608/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2838 - accuracy: 0.9068 - val_loss: 1.4549 - val_accuracy: 0.7429\n",
      "Epoch 609/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2807 - accuracy: 0.9068 - val_loss: 1.3028 - val_accuracy: 0.7429\n",
      "Epoch 610/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2617 - accuracy: 0.9247 - val_loss: 1.2728 - val_accuracy: 0.8143\n",
      "Epoch 611/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2732 - accuracy: 0.9176 - val_loss: 1.4557 - val_accuracy: 0.7429\n",
      "Epoch 612/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.2639 - accuracy: 0.9176 - val_loss: 1.3529 - val_accuracy: 0.7429\n",
      "Epoch 613/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2592 - accuracy: 0.9283 - val_loss: 1.3092 - val_accuracy: 0.7714\n",
      "Epoch 614/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.2603 - accuracy: 0.9283 - val_loss: 1.3722 - val_accuracy: 0.8000\n",
      "Epoch 615/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2567 - accuracy: 0.9211 - val_loss: 1.3616 - val_accuracy: 0.7714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2633 - accuracy: 0.9283 - val_loss: 1.3083 - val_accuracy: 0.8000\n",
      "Epoch 617/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2624 - accuracy: 0.9176 - val_loss: 1.3402 - val_accuracy: 0.7714\n",
      "Epoch 618/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.2448 - accuracy: 0.9319 - val_loss: 1.3424 - val_accuracy: 0.8000\n",
      "Epoch 619/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2482 - accuracy: 0.9068 - val_loss: 1.4025 - val_accuracy: 0.7571\n",
      "Epoch 620/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2580 - accuracy: 0.9211 - val_loss: 1.3374 - val_accuracy: 0.7857\n",
      "Epoch 621/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2444 - accuracy: 0.9247 - val_loss: 1.3926 - val_accuracy: 0.7571\n",
      "Epoch 622/1000\n",
      "279/279 [==============================] - 0s 59us/step - loss: 0.2430 - accuracy: 0.9283 - val_loss: 1.2955 - val_accuracy: 0.7714\n",
      "Epoch 623/1000\n",
      "279/279 [==============================] - 0s 58us/step - loss: 0.2527 - accuracy: 0.9247 - val_loss: 1.4199 - val_accuracy: 0.7143\n",
      "Epoch 624/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2673 - accuracy: 0.8961 - val_loss: 1.3562 - val_accuracy: 0.7714\n",
      "Epoch 625/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2859 - accuracy: 0.9140 - val_loss: 1.3564 - val_accuracy: 0.7571\n",
      "Epoch 626/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2604 - accuracy: 0.9068 - val_loss: 1.2971 - val_accuracy: 0.7857\n",
      "Epoch 627/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2525 - accuracy: 0.9283 - val_loss: 1.4718 - val_accuracy: 0.7143\n",
      "Epoch 628/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2787 - accuracy: 0.8961 - val_loss: 1.3176 - val_accuracy: 0.7857\n",
      "Epoch 629/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2725 - accuracy: 0.9104 - val_loss: 1.5176 - val_accuracy: 0.7286\n",
      "Epoch 630/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.2561 - accuracy: 0.9176 - val_loss: 1.2850 - val_accuracy: 0.7857\n",
      "Epoch 631/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.2542 - accuracy: 0.8996 - val_loss: 1.4980 - val_accuracy: 0.7143\n",
      "Epoch 632/1000\n",
      "279/279 [==============================] - 0s 73us/step - loss: 0.2489 - accuracy: 0.9283 - val_loss: 1.3329 - val_accuracy: 0.7571\n",
      "Epoch 633/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2408 - accuracy: 0.9176 - val_loss: 1.3576 - val_accuracy: 0.7857\n",
      "Epoch 634/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2608 - accuracy: 0.9176 - val_loss: 1.3284 - val_accuracy: 0.8286\n",
      "Epoch 635/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2606 - accuracy: 0.9247 - val_loss: 1.3429 - val_accuracy: 0.8143\n",
      "Epoch 636/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2355 - accuracy: 0.9355 - val_loss: 1.2847 - val_accuracy: 0.8000\n",
      "Epoch 637/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2420 - accuracy: 0.9211 - val_loss: 1.3853 - val_accuracy: 0.8000\n",
      "Epoch 638/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2444 - accuracy: 0.9104 - val_loss: 1.3363 - val_accuracy: 0.7429\n",
      "Epoch 639/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2713 - accuracy: 0.8925 - val_loss: 1.4901 - val_accuracy: 0.7000\n",
      "Epoch 640/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.2575 - accuracy: 0.9068 - val_loss: 1.3376 - val_accuracy: 0.8143\n",
      "Epoch 641/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2479 - accuracy: 0.8996 - val_loss: 1.4979 - val_accuracy: 0.7000\n",
      "Epoch 642/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2408 - accuracy: 0.9283 - val_loss: 1.3237 - val_accuracy: 0.7857\n",
      "Epoch 643/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2372 - accuracy: 0.9355 - val_loss: 1.3314 - val_accuracy: 0.8286\n",
      "Epoch 644/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2685 - accuracy: 0.8996 - val_loss: 1.3638 - val_accuracy: 0.8000\n",
      "Epoch 645/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2620 - accuracy: 0.9176 - val_loss: 1.5209 - val_accuracy: 0.6857\n",
      "Epoch 646/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2372 - accuracy: 0.9283 - val_loss: 1.3280 - val_accuracy: 0.8143\n",
      "Epoch 647/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2484 - accuracy: 0.9140 - val_loss: 1.5255 - val_accuracy: 0.6857\n",
      "Epoch 648/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2828 - accuracy: 0.8889 - val_loss: 1.3474 - val_accuracy: 0.7571\n",
      "Epoch 649/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2797 - accuracy: 0.9211 - val_loss: 1.3785 - val_accuracy: 0.7571\n",
      "Epoch 650/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2780 - accuracy: 0.8817 - val_loss: 1.3819 - val_accuracy: 0.8000\n",
      "Epoch 651/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2462 - accuracy: 0.9104 - val_loss: 1.3417 - val_accuracy: 0.8429\n",
      "Epoch 652/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2504 - accuracy: 0.9140 - val_loss: 1.4460 - val_accuracy: 0.7143\n",
      "Epoch 653/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2708 - accuracy: 0.9068 - val_loss: 1.4082 - val_accuracy: 0.7857\n",
      "Epoch 654/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2595 - accuracy: 0.9104 - val_loss: 1.4324 - val_accuracy: 0.7429\n",
      "Epoch 655/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2326 - accuracy: 0.9176 - val_loss: 1.3706 - val_accuracy: 0.8000\n",
      "Epoch 656/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2268 - accuracy: 0.9355 - val_loss: 1.3728 - val_accuracy: 0.8286\n",
      "Epoch 657/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2277 - accuracy: 0.9176 - val_loss: 1.4204 - val_accuracy: 0.7714\n",
      "Epoch 658/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2346 - accuracy: 0.9319 - val_loss: 1.3926 - val_accuracy: 0.8000\n",
      "Epoch 659/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2395 - accuracy: 0.9104 - val_loss: 1.3551 - val_accuracy: 0.8000\n",
      "Epoch 660/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2826 - accuracy: 0.8996 - val_loss: 1.5253 - val_accuracy: 0.6714\n",
      "Epoch 661/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2547 - accuracy: 0.9032 - val_loss: 1.4559 - val_accuracy: 0.7143\n",
      "Epoch 662/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2535 - accuracy: 0.9283 - val_loss: 1.3655 - val_accuracy: 0.7714\n",
      "Epoch 663/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.2820 - accuracy: 0.8710 - val_loss: 1.5058 - val_accuracy: 0.6714\n",
      "Epoch 664/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2524 - accuracy: 0.9140 - val_loss: 1.3206 - val_accuracy: 0.8000\n",
      "Epoch 665/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2567 - accuracy: 0.8925 - val_loss: 1.4277 - val_accuracy: 0.7857\n",
      "Epoch 666/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2474 - accuracy: 0.9247 - val_loss: 1.3817 - val_accuracy: 0.7571\n",
      "Epoch 667/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2554 - accuracy: 0.8853 - val_loss: 1.4182 - val_accuracy: 0.7714\n",
      "Epoch 668/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.2375 - accuracy: 0.9247 - val_loss: 1.4572 - val_accuracy: 0.7571\n",
      "Epoch 669/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2409 - accuracy: 0.9140 - val_loss: 1.3605 - val_accuracy: 0.8143\n",
      "Epoch 670/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2323 - accuracy: 0.9247 - val_loss: 1.3843 - val_accuracy: 0.8000\n",
      "Epoch 671/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.2272 - accuracy: 0.9104 - val_loss: 1.3698 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.2220 - accuracy: 0.9462 - val_loss: 1.3358 - val_accuracy: 0.8286\n",
      "Epoch 673/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2268 - accuracy: 0.9283 - val_loss: 1.4382 - val_accuracy: 0.7286\n",
      "Epoch 674/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2371 - accuracy: 0.9355 - val_loss: 1.4363 - val_accuracy: 0.8000\n",
      "Epoch 675/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2370 - accuracy: 0.9068 - val_loss: 1.3176 - val_accuracy: 0.8286\n",
      "Epoch 676/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2365 - accuracy: 0.9283 - val_loss: 1.3798 - val_accuracy: 0.8571\n",
      "Epoch 677/1000\n",
      "279/279 [==============================] - 0s 54us/step - loss: 0.2465 - accuracy: 0.8925 - val_loss: 1.3472 - val_accuracy: 0.8000\n",
      "Epoch 678/1000\n",
      "279/279 [==============================] - 0s 57us/step - loss: 0.2178 - accuracy: 0.9391 - val_loss: 1.4657 - val_accuracy: 0.7857\n",
      "Epoch 679/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2236 - accuracy: 0.9247 - val_loss: 1.4110 - val_accuracy: 0.8143\n",
      "Epoch 680/1000\n",
      "279/279 [==============================] - 0s 58us/step - loss: 0.2210 - accuracy: 0.9355 - val_loss: 1.3494 - val_accuracy: 0.8286\n",
      "Epoch 681/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.2274 - accuracy: 0.9068 - val_loss: 1.5113 - val_accuracy: 0.7714\n",
      "Epoch 682/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2554 - accuracy: 0.9140 - val_loss: 1.4008 - val_accuracy: 0.8143\n",
      "Epoch 683/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2378 - accuracy: 0.9068 - val_loss: 1.4451 - val_accuracy: 0.8143\n",
      "Epoch 684/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2398 - accuracy: 0.9211 - val_loss: 1.3892 - val_accuracy: 0.8143\n",
      "Epoch 685/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.2335 - accuracy: 0.9247 - val_loss: 1.3838 - val_accuracy: 0.8143\n",
      "Epoch 686/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2426 - accuracy: 0.9104 - val_loss: 1.3975 - val_accuracy: 0.8286\n",
      "Epoch 687/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2415 - accuracy: 0.9319 - val_loss: 1.3758 - val_accuracy: 0.8143\n",
      "Epoch 688/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2360 - accuracy: 0.9283 - val_loss: 1.5191 - val_accuracy: 0.7571\n",
      "Epoch 689/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.2341 - accuracy: 0.9247 - val_loss: 1.4672 - val_accuracy: 0.7714\n",
      "Epoch 690/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2218 - accuracy: 0.9283 - val_loss: 1.4270 - val_accuracy: 0.8286\n",
      "Epoch 691/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2253 - accuracy: 0.9283 - val_loss: 1.3393 - val_accuracy: 0.8286\n",
      "Epoch 692/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2446 - accuracy: 0.9104 - val_loss: 1.5761 - val_accuracy: 0.6857\n",
      "Epoch 693/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2339 - accuracy: 0.9247 - val_loss: 1.4460 - val_accuracy: 0.7714\n",
      "Epoch 694/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.2211 - accuracy: 0.9283 - val_loss: 1.4026 - val_accuracy: 0.8429\n",
      "Epoch 695/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2196 - accuracy: 0.9211 - val_loss: 1.4431 - val_accuracy: 0.7571\n",
      "Epoch 696/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2279 - accuracy: 0.9319 - val_loss: 1.3906 - val_accuracy: 0.8286\n",
      "Epoch 697/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.2243 - accuracy: 0.9247 - val_loss: 1.4033 - val_accuracy: 0.8429\n",
      "Epoch 698/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.2259 - accuracy: 0.9427 - val_loss: 1.5219 - val_accuracy: 0.6857\n",
      "Epoch 699/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2203 - accuracy: 0.9211 - val_loss: 1.4084 - val_accuracy: 0.8143\n",
      "Epoch 700/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2375 - accuracy: 0.9140 - val_loss: 1.4176 - val_accuracy: 0.7857\n",
      "Epoch 701/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2371 - accuracy: 0.9032 - val_loss: 1.4085 - val_accuracy: 0.7714\n",
      "Epoch 702/1000\n",
      "279/279 [==============================] - 0s 92us/step - loss: 0.2222 - accuracy: 0.9427 - val_loss: 1.4412 - val_accuracy: 0.8000\n",
      "Epoch 703/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2296 - accuracy: 0.9104 - val_loss: 1.4723 - val_accuracy: 0.7857\n",
      "Epoch 704/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2217 - accuracy: 0.9247 - val_loss: 1.4244 - val_accuracy: 0.7571\n",
      "Epoch 705/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2507 - accuracy: 0.9247 - val_loss: 1.4250 - val_accuracy: 0.8000\n",
      "Epoch 706/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2474 - accuracy: 0.9068 - val_loss: 1.5141 - val_accuracy: 0.7857\n",
      "Epoch 707/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2233 - accuracy: 0.9247 - val_loss: 1.4175 - val_accuracy: 0.8143\n",
      "Epoch 708/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2104 - accuracy: 0.9498 - val_loss: 1.3997 - val_accuracy: 0.8571\n",
      "Epoch 709/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2334 - accuracy: 0.8996 - val_loss: 1.4226 - val_accuracy: 0.8143\n",
      "Epoch 710/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2036 - accuracy: 0.9355 - val_loss: 1.5498 - val_accuracy: 0.7429\n",
      "Epoch 711/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2087 - accuracy: 0.9462 - val_loss: 1.4060 - val_accuracy: 0.8000\n",
      "Epoch 712/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2060 - accuracy: 0.9355 - val_loss: 1.4599 - val_accuracy: 0.8143\n",
      "Epoch 713/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2076 - accuracy: 0.9319 - val_loss: 1.4132 - val_accuracy: 0.8429\n",
      "Epoch 714/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2101 - accuracy: 0.9247 - val_loss: 1.4352 - val_accuracy: 0.8000\n",
      "Epoch 715/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2091 - accuracy: 0.9391 - val_loss: 1.4555 - val_accuracy: 0.7857\n",
      "Epoch 716/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2026 - accuracy: 0.9391 - val_loss: 1.3900 - val_accuracy: 0.8429\n",
      "Epoch 717/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.2132 - accuracy: 0.9247 - val_loss: 1.5196 - val_accuracy: 0.8143\n",
      "Epoch 718/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2288 - accuracy: 0.9355 - val_loss: 1.4474 - val_accuracy: 0.7714\n",
      "Epoch 719/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2642 - accuracy: 0.9032 - val_loss: 1.4423 - val_accuracy: 0.8000\n",
      "Epoch 720/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2332 - accuracy: 0.9355 - val_loss: 1.5364 - val_accuracy: 0.7143\n",
      "Epoch 721/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.2586 - accuracy: 0.9068 - val_loss: 1.4427 - val_accuracy: 0.8143\n",
      "Epoch 722/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2261 - accuracy: 0.9247 - val_loss: 1.5994 - val_accuracy: 0.7571\n",
      "Epoch 723/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2412 - accuracy: 0.9140 - val_loss: 1.4449 - val_accuracy: 0.8143\n",
      "Epoch 724/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2121 - accuracy: 0.9176 - val_loss: 1.4516 - val_accuracy: 0.8286\n",
      "Epoch 725/1000\n",
      "279/279 [==============================] - 0s 71us/step - loss: 0.2127 - accuracy: 0.9355 - val_loss: 1.4839 - val_accuracy: 0.7429\n",
      "Epoch 726/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2060 - accuracy: 0.9462 - val_loss: 1.4222 - val_accuracy: 0.7857\n",
      "Epoch 727/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2130 - accuracy: 0.9211 - val_loss: 1.4448 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.2231 - accuracy: 0.9319 - val_loss: 1.4798 - val_accuracy: 0.7857\n",
      "Epoch 729/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2569 - accuracy: 0.8781 - val_loss: 1.4891 - val_accuracy: 0.8286\n",
      "Epoch 730/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2225 - accuracy: 0.9283 - val_loss: 1.4620 - val_accuracy: 0.7857\n",
      "Epoch 731/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2170 - accuracy: 0.9247 - val_loss: 1.4495 - val_accuracy: 0.7714\n",
      "Epoch 732/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2498 - accuracy: 0.8925 - val_loss: 1.5152 - val_accuracy: 0.7857\n",
      "Epoch 733/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.1986 - accuracy: 0.9534 - val_loss: 1.4047 - val_accuracy: 0.8143\n",
      "Epoch 734/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2085 - accuracy: 0.9355 - val_loss: 1.3961 - val_accuracy: 0.8143\n",
      "Epoch 735/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2016 - accuracy: 0.9427 - val_loss: 1.5130 - val_accuracy: 0.7571\n",
      "Epoch 736/1000\n",
      "279/279 [==============================] - 0s 57us/step - loss: 0.2134 - accuracy: 0.9355 - val_loss: 1.4506 - val_accuracy: 0.8143\n",
      "Epoch 737/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2279 - accuracy: 0.9319 - val_loss: 1.4636 - val_accuracy: 0.8143\n",
      "Epoch 738/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.2466 - accuracy: 0.8925 - val_loss: 1.7437 - val_accuracy: 0.6857\n",
      "Epoch 739/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.2704 - accuracy: 0.8996 - val_loss: 1.3720 - val_accuracy: 0.8286\n",
      "Epoch 740/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2307 - accuracy: 0.9140 - val_loss: 1.5088 - val_accuracy: 0.8000\n",
      "Epoch 741/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1981 - accuracy: 0.9319 - val_loss: 1.4635 - val_accuracy: 0.7571\n",
      "Epoch 742/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2065 - accuracy: 0.9319 - val_loss: 1.4374 - val_accuracy: 0.8286\n",
      "Epoch 743/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.1996 - accuracy: 0.9319 - val_loss: 1.4865 - val_accuracy: 0.7714\n",
      "Epoch 744/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2088 - accuracy: 0.9283 - val_loss: 1.4564 - val_accuracy: 0.8000\n",
      "Epoch 745/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2162 - accuracy: 0.9247 - val_loss: 1.4614 - val_accuracy: 0.8143\n",
      "Epoch 746/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2486 - accuracy: 0.9104 - val_loss: 1.4708 - val_accuracy: 0.7857\n",
      "Epoch 747/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2354 - accuracy: 0.9462 - val_loss: 1.5861 - val_accuracy: 0.7143\n",
      "Epoch 748/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2304 - accuracy: 0.9247 - val_loss: 1.4832 - val_accuracy: 0.7857\n",
      "Epoch 749/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2130 - accuracy: 0.9319 - val_loss: 1.4802 - val_accuracy: 0.7857\n",
      "Epoch 750/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2105 - accuracy: 0.9427 - val_loss: 1.4393 - val_accuracy: 0.8143\n",
      "Epoch 751/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.2048 - accuracy: 0.9355 - val_loss: 1.5492 - val_accuracy: 0.8000\n",
      "Epoch 752/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2164 - accuracy: 0.9247 - val_loss: 1.4917 - val_accuracy: 0.7429\n",
      "Epoch 753/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2171 - accuracy: 0.9140 - val_loss: 1.4510 - val_accuracy: 0.8286\n",
      "Epoch 754/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2119 - accuracy: 0.9211 - val_loss: 1.4468 - val_accuracy: 0.8143\n",
      "Epoch 755/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1990 - accuracy: 0.9247 - val_loss: 1.4892 - val_accuracy: 0.8000\n",
      "Epoch 756/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2018 - accuracy: 0.9427 - val_loss: 1.4998 - val_accuracy: 0.7571\n",
      "Epoch 757/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2143 - accuracy: 0.9140 - val_loss: 1.4896 - val_accuracy: 0.8143\n",
      "Epoch 758/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1929 - accuracy: 0.9534 - val_loss: 1.4233 - val_accuracy: 0.8429\n",
      "Epoch 759/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1893 - accuracy: 0.9391 - val_loss: 1.5227 - val_accuracy: 0.7571\n",
      "Epoch 760/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1925 - accuracy: 0.9534 - val_loss: 1.4572 - val_accuracy: 0.8000\n",
      "Epoch 761/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.2040 - accuracy: 0.9247 - val_loss: 1.5256 - val_accuracy: 0.7286\n",
      "Epoch 762/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2077 - accuracy: 0.9427 - val_loss: 1.3596 - val_accuracy: 0.8286\n",
      "Epoch 763/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2040 - accuracy: 0.9283 - val_loss: 1.3783 - val_accuracy: 0.8429\n",
      "Epoch 764/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2167 - accuracy: 0.9247 - val_loss: 1.4422 - val_accuracy: 0.8143\n",
      "Epoch 765/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1997 - accuracy: 0.9247 - val_loss: 1.4957 - val_accuracy: 0.7143\n",
      "Epoch 766/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2044 - accuracy: 0.9319 - val_loss: 1.4800 - val_accuracy: 0.8000\n",
      "Epoch 767/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1978 - accuracy: 0.9462 - val_loss: 1.3889 - val_accuracy: 0.8000\n",
      "Epoch 768/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1889 - accuracy: 0.9355 - val_loss: 1.5408 - val_accuracy: 0.7571\n",
      "Epoch 769/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1984 - accuracy: 0.9391 - val_loss: 1.4622 - val_accuracy: 0.8286\n",
      "Epoch 770/1000\n",
      "279/279 [==============================] - 0s 58us/step - loss: 0.2131 - accuracy: 0.9176 - val_loss: 1.3898 - val_accuracy: 0.8286\n",
      "Epoch 771/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2047 - accuracy: 0.9104 - val_loss: 1.5438 - val_accuracy: 0.7714\n",
      "Epoch 772/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1928 - accuracy: 0.9462 - val_loss: 1.4702 - val_accuracy: 0.8286\n",
      "Epoch 773/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1998 - accuracy: 0.9319 - val_loss: 1.5301 - val_accuracy: 0.8286\n",
      "Epoch 774/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2068 - accuracy: 0.9247 - val_loss: 1.4787 - val_accuracy: 0.7571\n",
      "Epoch 775/1000\n",
      "279/279 [==============================] - 0s 101us/step - loss: 0.1848 - accuracy: 0.9534 - val_loss: 1.4684 - val_accuracy: 0.8143\n",
      "Epoch 776/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1950 - accuracy: 0.9211 - val_loss: 1.4692 - val_accuracy: 0.8286\n",
      "Epoch 777/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2098 - accuracy: 0.9283 - val_loss: 1.5547 - val_accuracy: 0.7286\n",
      "Epoch 778/1000\n",
      "279/279 [==============================] - 0s 84us/step - loss: 0.2001 - accuracy: 0.9427 - val_loss: 1.5525 - val_accuracy: 0.8000\n",
      "Epoch 779/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2050 - accuracy: 0.9211 - val_loss: 1.4546 - val_accuracy: 0.8286\n",
      "Epoch 780/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2159 - accuracy: 0.8996 - val_loss: 1.4427 - val_accuracy: 0.8429\n",
      "Epoch 781/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1931 - accuracy: 0.9319 - val_loss: 1.5566 - val_accuracy: 0.7857\n",
      "Epoch 782/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1950 - accuracy: 0.9319 - val_loss: 1.4751 - val_accuracy: 0.8143\n",
      "Epoch 783/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.2031 - accuracy: 0.9211 - val_loss: 1.5419 - val_accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1989 - accuracy: 0.9283 - val_loss: 1.4532 - val_accuracy: 0.8143\n",
      "Epoch 785/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1908 - accuracy: 0.9498 - val_loss: 1.5044 - val_accuracy: 0.7714\n",
      "Epoch 786/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2109 - accuracy: 0.9211 - val_loss: 1.4690 - val_accuracy: 0.8429\n",
      "Epoch 787/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1996 - accuracy: 0.9427 - val_loss: 1.5440 - val_accuracy: 0.7571\n",
      "Epoch 788/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2011 - accuracy: 0.9319 - val_loss: 1.4450 - val_accuracy: 0.8000\n",
      "Epoch 789/1000\n",
      "279/279 [==============================] - 0s 57us/step - loss: 0.1991 - accuracy: 0.9283 - val_loss: 1.6148 - val_accuracy: 0.8000\n",
      "Epoch 790/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2212 - accuracy: 0.9140 - val_loss: 1.4772 - val_accuracy: 0.8286\n",
      "Epoch 791/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2144 - accuracy: 0.9247 - val_loss: 1.4552 - val_accuracy: 0.8143\n",
      "Epoch 792/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2077 - accuracy: 0.9319 - val_loss: 1.5001 - val_accuracy: 0.7571\n",
      "Epoch 793/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2142 - accuracy: 0.9283 - val_loss: 1.7479 - val_accuracy: 0.7571\n",
      "Epoch 794/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2223 - accuracy: 0.9247 - val_loss: 1.6995 - val_accuracy: 0.7286\n",
      "Epoch 795/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2121 - accuracy: 0.9355 - val_loss: 1.4284 - val_accuracy: 0.7571\n",
      "Epoch 796/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2298 - accuracy: 0.9176 - val_loss: 1.5292 - val_accuracy: 0.8429\n",
      "Epoch 797/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.2606 - accuracy: 0.8961 - val_loss: 1.6045 - val_accuracy: 0.7429\n",
      "Epoch 798/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2318 - accuracy: 0.9211 - val_loss: 1.5188 - val_accuracy: 0.7857\n",
      "Epoch 799/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2106 - accuracy: 0.9283 - val_loss: 1.5850 - val_accuracy: 0.7571\n",
      "Epoch 800/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1983 - accuracy: 0.9283 - val_loss: 1.5764 - val_accuracy: 0.7857\n",
      "Epoch 801/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1799 - accuracy: 0.9427 - val_loss: 1.5158 - val_accuracy: 0.8000\n",
      "Epoch 802/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.1870 - accuracy: 0.9391 - val_loss: 1.6000 - val_accuracy: 0.8143\n",
      "Epoch 803/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1943 - accuracy: 0.9391 - val_loss: 1.5681 - val_accuracy: 0.7143\n",
      "Epoch 804/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.1840 - accuracy: 0.9427 - val_loss: 1.5095 - val_accuracy: 0.8286\n",
      "Epoch 805/1000\n",
      "279/279 [==============================] - 0s 59us/step - loss: 0.1808 - accuracy: 0.9427 - val_loss: 1.6155 - val_accuracy: 0.7571\n",
      "Epoch 806/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1888 - accuracy: 0.9176 - val_loss: 1.5052 - val_accuracy: 0.8286\n",
      "Epoch 807/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2019 - accuracy: 0.9355 - val_loss: 1.5926 - val_accuracy: 0.7857\n",
      "Epoch 808/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1932 - accuracy: 0.9427 - val_loss: 1.6016 - val_accuracy: 0.8000\n",
      "Epoch 809/1000\n",
      "279/279 [==============================] - 0s 59us/step - loss: 0.1864 - accuracy: 0.9355 - val_loss: 1.5174 - val_accuracy: 0.8286\n",
      "Epoch 810/1000\n",
      "279/279 [==============================] - 0s 60us/step - loss: 0.1976 - accuracy: 0.9211 - val_loss: 1.6377 - val_accuracy: 0.7286\n",
      "Epoch 811/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2076 - accuracy: 0.9283 - val_loss: 1.5261 - val_accuracy: 0.8000\n",
      "Epoch 812/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.1937 - accuracy: 0.9462 - val_loss: 1.5350 - val_accuracy: 0.8286\n",
      "Epoch 813/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2048 - accuracy: 0.9355 - val_loss: 1.6335 - val_accuracy: 0.7571\n",
      "Epoch 814/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2027 - accuracy: 0.9283 - val_loss: 1.5312 - val_accuracy: 0.8143\n",
      "Epoch 815/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2317 - accuracy: 0.9176 - val_loss: 1.4817 - val_accuracy: 0.8000\n",
      "Epoch 816/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2148 - accuracy: 0.9140 - val_loss: 1.6328 - val_accuracy: 0.7286\n",
      "Epoch 817/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2059 - accuracy: 0.9140 - val_loss: 1.4512 - val_accuracy: 0.8429\n",
      "Epoch 818/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.1920 - accuracy: 0.9391 - val_loss: 1.5612 - val_accuracy: 0.7857\n",
      "Epoch 819/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2048 - accuracy: 0.9068 - val_loss: 1.5321 - val_accuracy: 0.8143\n",
      "Epoch 820/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1853 - accuracy: 0.9462 - val_loss: 1.4937 - val_accuracy: 0.8000\n",
      "Epoch 821/1000\n",
      "279/279 [==============================] - 0s 78us/step - loss: 0.1804 - accuracy: 0.9462 - val_loss: 1.5573 - val_accuracy: 0.8143\n",
      "Epoch 822/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1890 - accuracy: 0.9355 - val_loss: 1.4454 - val_accuracy: 0.8429\n",
      "Epoch 823/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2034 - accuracy: 0.9283 - val_loss: 1.7614 - val_accuracy: 0.7143\n",
      "Epoch 824/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1857 - accuracy: 0.9462 - val_loss: 1.4347 - val_accuracy: 0.8143\n",
      "Epoch 825/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2027 - accuracy: 0.9283 - val_loss: 1.5952 - val_accuracy: 0.7571\n",
      "Epoch 826/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1907 - accuracy: 0.9319 - val_loss: 1.5678 - val_accuracy: 0.8000\n",
      "Epoch 827/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1694 - accuracy: 0.9462 - val_loss: 1.4607 - val_accuracy: 0.8143\n",
      "Epoch 828/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1780 - accuracy: 0.9391 - val_loss: 1.5697 - val_accuracy: 0.8143\n",
      "Epoch 829/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1747 - accuracy: 0.9427 - val_loss: 1.4918 - val_accuracy: 0.8000\n",
      "Epoch 830/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1817 - accuracy: 0.9534 - val_loss: 1.5750 - val_accuracy: 0.8143\n",
      "Epoch 831/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.1787 - accuracy: 0.9462 - val_loss: 1.5488 - val_accuracy: 0.7857\n",
      "Epoch 832/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1744 - accuracy: 0.9498 - val_loss: 1.4785 - val_accuracy: 0.8286\n",
      "Epoch 833/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1858 - accuracy: 0.9283 - val_loss: 1.5189 - val_accuracy: 0.8286\n",
      "Epoch 834/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1846 - accuracy: 0.9283 - val_loss: 1.5069 - val_accuracy: 0.7714\n",
      "Epoch 835/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1999 - accuracy: 0.9247 - val_loss: 1.6752 - val_accuracy: 0.7429\n",
      "Epoch 836/1000\n",
      "279/279 [==============================] - 0s 78us/step - loss: 0.2023 - accuracy: 0.9140 - val_loss: 1.4759 - val_accuracy: 0.8143\n",
      "Epoch 837/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.2066 - accuracy: 0.9355 - val_loss: 1.5671 - val_accuracy: 0.7286\n",
      "Epoch 838/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1881 - accuracy: 0.9176 - val_loss: 1.5358 - val_accuracy: 0.8143\n",
      "Epoch 839/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.2009 - accuracy: 0.9391 - val_loss: 1.4580 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1992 - accuracy: 0.9319 - val_loss: 1.6914 - val_accuracy: 0.7143\n",
      "Epoch 841/1000\n",
      "279/279 [==============================] - 0s 73us/step - loss: 0.1849 - accuracy: 0.9319 - val_loss: 1.5732 - val_accuracy: 0.8286\n",
      "Epoch 842/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.2312 - accuracy: 0.9068 - val_loss: 1.5719 - val_accuracy: 0.7429\n",
      "Epoch 843/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.2046 - accuracy: 0.9283 - val_loss: 1.5661 - val_accuracy: 0.7714\n",
      "Epoch 844/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1948 - accuracy: 0.9211 - val_loss: 1.6245 - val_accuracy: 0.8000\n",
      "Epoch 845/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.1883 - accuracy: 0.9498 - val_loss: 1.5051 - val_accuracy: 0.8143\n",
      "Epoch 846/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1647 - accuracy: 0.9427 - val_loss: 1.5167 - val_accuracy: 0.8286\n",
      "Epoch 847/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1687 - accuracy: 0.9498 - val_loss: 1.5397 - val_accuracy: 0.8000\n",
      "Epoch 848/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1757 - accuracy: 0.9391 - val_loss: 1.5290 - val_accuracy: 0.8286\n",
      "Epoch 849/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1640 - accuracy: 0.9498 - val_loss: 1.4987 - val_accuracy: 0.8286\n",
      "Epoch 850/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.1651 - accuracy: 0.9462 - val_loss: 1.5608 - val_accuracy: 0.8000\n",
      "Epoch 851/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1670 - accuracy: 0.9570 - val_loss: 1.4458 - val_accuracy: 0.8571\n",
      "Epoch 852/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1670 - accuracy: 0.9391 - val_loss: 1.5868 - val_accuracy: 0.8000\n",
      "Epoch 853/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1793 - accuracy: 0.9355 - val_loss: 1.5170 - val_accuracy: 0.8143\n",
      "Epoch 854/1000\n",
      "279/279 [==============================] - 0s 106us/step - loss: 0.1782 - accuracy: 0.9391 - val_loss: 1.4771 - val_accuracy: 0.8429\n",
      "Epoch 855/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.1680 - accuracy: 0.9498 - val_loss: 1.5932 - val_accuracy: 0.7571\n",
      "Epoch 856/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2141 - accuracy: 0.9140 - val_loss: 1.5008 - val_accuracy: 0.8286\n",
      "Epoch 857/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1992 - accuracy: 0.9283 - val_loss: 1.4566 - val_accuracy: 0.8143\n",
      "Epoch 858/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1892 - accuracy: 0.9391 - val_loss: 1.6452 - val_accuracy: 0.7571\n",
      "Epoch 859/1000\n",
      "279/279 [==============================] - 0s 64us/step - loss: 0.2076 - accuracy: 0.8996 - val_loss: 1.5477 - val_accuracy: 0.8000\n",
      "Epoch 860/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2149 - accuracy: 0.9427 - val_loss: 1.5036 - val_accuracy: 0.8286\n",
      "Epoch 861/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.1836 - accuracy: 0.9391 - val_loss: 1.6071 - val_accuracy: 0.8000\n",
      "Epoch 862/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1707 - accuracy: 0.9391 - val_loss: 1.5048 - val_accuracy: 0.8143\n",
      "Epoch 863/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1671 - accuracy: 0.9462 - val_loss: 1.6265 - val_accuracy: 0.7857\n",
      "Epoch 864/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1740 - accuracy: 0.9427 - val_loss: 1.4990 - val_accuracy: 0.8143\n",
      "Epoch 865/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1598 - accuracy: 0.9534 - val_loss: 1.5899 - val_accuracy: 0.7714\n",
      "Epoch 866/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1719 - accuracy: 0.9498 - val_loss: 1.6530 - val_accuracy: 0.7571\n",
      "Epoch 867/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.1827 - accuracy: 0.9211 - val_loss: 1.5721 - val_accuracy: 0.8286\n",
      "Epoch 868/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1958 - accuracy: 0.9211 - val_loss: 1.5150 - val_accuracy: 0.8571\n",
      "Epoch 869/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1716 - accuracy: 0.9355 - val_loss: 1.6008 - val_accuracy: 0.8000\n",
      "Epoch 870/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1727 - accuracy: 0.9427 - val_loss: 1.5265 - val_accuracy: 0.8143\n",
      "Epoch 871/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1818 - accuracy: 0.9498 - val_loss: 1.5839 - val_accuracy: 0.7714\n",
      "Epoch 872/1000\n",
      "279/279 [==============================] - 0s 73us/step - loss: 0.1758 - accuracy: 0.9427 - val_loss: 1.5851 - val_accuracy: 0.7857\n",
      "Epoch 873/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1669 - accuracy: 0.9427 - val_loss: 1.5756 - val_accuracy: 0.8143\n",
      "Epoch 874/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1732 - accuracy: 0.9319 - val_loss: 1.5069 - val_accuracy: 0.7714\n",
      "Epoch 875/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.1866 - accuracy: 0.9427 - val_loss: 1.6625 - val_accuracy: 0.7857\n",
      "Epoch 876/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2135 - accuracy: 0.9068 - val_loss: 1.5546 - val_accuracy: 0.8143\n",
      "Epoch 877/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2033 - accuracy: 0.9283 - val_loss: 1.6428 - val_accuracy: 0.7571\n",
      "Epoch 878/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.2007 - accuracy: 0.9211 - val_loss: 1.5966 - val_accuracy: 0.8143\n",
      "Epoch 879/1000\n",
      "279/279 [==============================] - 0s 88us/step - loss: 0.1688 - accuracy: 0.9534 - val_loss: 1.5802 - val_accuracy: 0.8000\n",
      "Epoch 880/1000\n",
      "279/279 [==============================] - 0s 69us/step - loss: 0.1637 - accuracy: 0.9391 - val_loss: 1.5372 - val_accuracy: 0.8143\n",
      "Epoch 881/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1683 - accuracy: 0.9462 - val_loss: 1.5642 - val_accuracy: 0.8286\n",
      "Epoch 882/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1690 - accuracy: 0.9391 - val_loss: 1.5848 - val_accuracy: 0.8000\n",
      "Epoch 883/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.1723 - accuracy: 0.9462 - val_loss: 1.5476 - val_accuracy: 0.7857\n",
      "Epoch 884/1000\n",
      "279/279 [==============================] - 0s 71us/step - loss: 0.1848 - accuracy: 0.9391 - val_loss: 1.5796 - val_accuracy: 0.8000\n",
      "Epoch 885/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1847 - accuracy: 0.9283 - val_loss: 1.7152 - val_accuracy: 0.7571\n",
      "Epoch 886/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2230 - accuracy: 0.8996 - val_loss: 1.6493 - val_accuracy: 0.8000\n",
      "Epoch 887/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1745 - accuracy: 0.9247 - val_loss: 1.5286 - val_accuracy: 0.8143\n",
      "Epoch 888/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1639 - accuracy: 0.9462 - val_loss: 1.6107 - val_accuracy: 0.8000\n",
      "Epoch 889/1000\n",
      "279/279 [==============================] - 0s 71us/step - loss: 0.1682 - accuracy: 0.9355 - val_loss: 1.4959 - val_accuracy: 0.8143\n",
      "Epoch 890/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1796 - accuracy: 0.9427 - val_loss: 1.5990 - val_accuracy: 0.7714\n",
      "Epoch 891/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1822 - accuracy: 0.9319 - val_loss: 1.5938 - val_accuracy: 0.8143\n",
      "Epoch 892/1000\n",
      "279/279 [==============================] - 0s 63us/step - loss: 0.1646 - accuracy: 0.9498 - val_loss: 1.5792 - val_accuracy: 0.8143\n",
      "Epoch 893/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.1706 - accuracy: 0.9462 - val_loss: 1.5103 - val_accuracy: 0.7714\n",
      "Epoch 894/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1615 - accuracy: 0.9534 - val_loss: 1.6115 - val_accuracy: 0.8000\n",
      "Epoch 895/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1787 - accuracy: 0.9319 - val_loss: 1.4954 - val_accuracy: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.1701 - accuracy: 0.9462 - val_loss: 1.6748 - val_accuracy: 0.8143\n",
      "Epoch 897/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1742 - accuracy: 0.9391 - val_loss: 1.5452 - val_accuracy: 0.8143\n",
      "Epoch 898/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1687 - accuracy: 0.9534 - val_loss: 1.6277 - val_accuracy: 0.8143\n",
      "Epoch 899/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1653 - accuracy: 0.9319 - val_loss: 1.5289 - val_accuracy: 0.8286\n",
      "Epoch 900/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1785 - accuracy: 0.9355 - val_loss: 1.5401 - val_accuracy: 0.8429\n",
      "Epoch 901/1000\n",
      "279/279 [==============================] - 0s 61us/step - loss: 0.1674 - accuracy: 0.9283 - val_loss: 1.5820 - val_accuracy: 0.7857\n",
      "Epoch 902/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1615 - accuracy: 0.9498 - val_loss: 1.4999 - val_accuracy: 0.8000\n",
      "Epoch 903/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.1791 - accuracy: 0.9247 - val_loss: 1.6516 - val_accuracy: 0.8000\n",
      "Epoch 904/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1678 - accuracy: 0.9427 - val_loss: 1.5697 - val_accuracy: 0.7571\n",
      "Epoch 905/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1717 - accuracy: 0.9498 - val_loss: 1.5901 - val_accuracy: 0.8143\n",
      "Epoch 906/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1620 - accuracy: 0.9427 - val_loss: 1.5598 - val_accuracy: 0.7857\n",
      "Epoch 907/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1576 - accuracy: 0.9606 - val_loss: 1.5694 - val_accuracy: 0.8143\n",
      "Epoch 908/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1672 - accuracy: 0.9211 - val_loss: 1.5701 - val_accuracy: 0.8286\n",
      "Epoch 909/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1633 - accuracy: 0.9355 - val_loss: 1.5978 - val_accuracy: 0.7857\n",
      "Epoch 910/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1747 - accuracy: 0.9462 - val_loss: 1.6125 - val_accuracy: 0.8143\n",
      "Epoch 911/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1636 - accuracy: 0.9319 - val_loss: 1.5599 - val_accuracy: 0.8000\n",
      "Epoch 912/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.1674 - accuracy: 0.9355 - val_loss: 1.7168 - val_accuracy: 0.7286\n",
      "Epoch 913/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1730 - accuracy: 0.9319 - val_loss: 1.6286 - val_accuracy: 0.8000\n",
      "Epoch 914/1000\n",
      "279/279 [==============================] - 0s 65us/step - loss: 0.1678 - accuracy: 0.9534 - val_loss: 1.5671 - val_accuracy: 0.8429\n",
      "Epoch 915/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1673 - accuracy: 0.9391 - val_loss: 1.6926 - val_accuracy: 0.7714\n",
      "Epoch 916/1000\n",
      "279/279 [==============================] - 0s 66us/step - loss: 0.1748 - accuracy: 0.9462 - val_loss: 1.6056 - val_accuracy: 0.8143\n",
      "Epoch 917/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.1563 - accuracy: 0.9534 - val_loss: 1.5912 - val_accuracy: 0.8143\n",
      "Epoch 918/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1625 - accuracy: 0.9534 - val_loss: 1.5380 - val_accuracy: 0.7857\n",
      "Epoch 919/1000\n",
      "279/279 [==============================] - 0s 90us/step - loss: 0.1835 - accuracy: 0.9283 - val_loss: 1.6322 - val_accuracy: 0.8143\n",
      "Epoch 920/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1756 - accuracy: 0.9391 - val_loss: 1.4992 - val_accuracy: 0.8429\n",
      "Epoch 921/1000\n",
      "279/279 [==============================] - 0s 70us/step - loss: 0.1776 - accuracy: 0.9498 - val_loss: 1.7718 - val_accuracy: 0.7143\n",
      "Epoch 922/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.1769 - accuracy: 0.9391 - val_loss: 1.5434 - val_accuracy: 0.8143\n",
      "Epoch 923/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1557 - accuracy: 0.9427 - val_loss: 1.6287 - val_accuracy: 0.8000\n",
      "Epoch 924/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1544 - accuracy: 0.9606 - val_loss: 1.6226 - val_accuracy: 0.7714\n",
      "Epoch 925/1000\n",
      "279/279 [==============================] - 0s 88us/step - loss: 0.1623 - accuracy: 0.9427 - val_loss: 1.6002 - val_accuracy: 0.8000\n",
      "Epoch 926/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1513 - accuracy: 0.9534 - val_loss: 1.6224 - val_accuracy: 0.8000\n",
      "Epoch 927/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1501 - accuracy: 0.9498 - val_loss: 1.6591 - val_accuracy: 0.7571\n",
      "Epoch 928/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1639 - accuracy: 0.9462 - val_loss: 1.5260 - val_accuracy: 0.8429\n",
      "Epoch 929/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1748 - accuracy: 0.9211 - val_loss: 1.7777 - val_accuracy: 0.7857\n",
      "Epoch 930/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.2069 - accuracy: 0.9104 - val_loss: 1.5441 - val_accuracy: 0.8286\n",
      "Epoch 931/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1795 - accuracy: 0.9319 - val_loss: 1.6101 - val_accuracy: 0.7857\n",
      "Epoch 932/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1820 - accuracy: 0.9391 - val_loss: 1.7028 - val_accuracy: 0.7143\n",
      "Epoch 933/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1752 - accuracy: 0.9498 - val_loss: 1.7030 - val_accuracy: 0.7429\n",
      "Epoch 934/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1679 - accuracy: 0.9462 - val_loss: 1.6568 - val_accuracy: 0.8000\n",
      "Epoch 935/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1625 - accuracy: 0.9462 - val_loss: 1.5611 - val_accuracy: 0.8000\n",
      "Epoch 936/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1650 - accuracy: 0.9462 - val_loss: 1.6842 - val_accuracy: 0.7857\n",
      "Epoch 937/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.1721 - accuracy: 0.9319 - val_loss: 1.6729 - val_accuracy: 0.8143\n",
      "Epoch 938/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1754 - accuracy: 0.9498 - val_loss: 1.5104 - val_accuracy: 0.8286\n",
      "Epoch 939/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1640 - accuracy: 0.9319 - val_loss: 1.7076 - val_accuracy: 0.8143\n",
      "Epoch 940/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.1487 - accuracy: 0.9498 - val_loss: 1.5780 - val_accuracy: 0.7857\n",
      "Epoch 941/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1558 - accuracy: 0.9534 - val_loss: 1.6301 - val_accuracy: 0.7714\n",
      "Epoch 942/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1477 - accuracy: 0.9462 - val_loss: 1.5936 - val_accuracy: 0.7857\n",
      "Epoch 943/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1614 - accuracy: 0.9498 - val_loss: 1.6341 - val_accuracy: 0.8143\n",
      "Epoch 944/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1860 - accuracy: 0.9247 - val_loss: 1.5262 - val_accuracy: 0.8143\n",
      "Epoch 945/1000\n",
      "279/279 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.87 - 0s 72us/step - loss: 0.1576 - accuracy: 0.9391 - val_loss: 1.6148 - val_accuracy: 0.8000\n",
      "Epoch 946/1000\n",
      "279/279 [==============================] - 0s 101us/step - loss: 0.1665 - accuracy: 0.9355 - val_loss: 1.6925 - val_accuracy: 0.8000\n",
      "Epoch 947/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1682 - accuracy: 0.9247 - val_loss: 1.5611 - val_accuracy: 0.8143\n",
      "Epoch 948/1000\n",
      "279/279 [==============================] - 0s 78us/step - loss: 0.1641 - accuracy: 0.9427 - val_loss: 1.6740 - val_accuracy: 0.7857\n",
      "Epoch 949/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1647 - accuracy: 0.9606 - val_loss: 1.5628 - val_accuracy: 0.8286\n",
      "Epoch 950/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1877 - accuracy: 0.9391 - val_loss: 1.6492 - val_accuracy: 0.7143\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279/279 [==============================] - 0s 74us/step - loss: 0.1740 - accuracy: 0.9355 - val_loss: 1.7227 - val_accuracy: 0.8000\n",
      "Epoch 952/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1642 - accuracy: 0.9570 - val_loss: 1.5842 - val_accuracy: 0.8143\n",
      "Epoch 953/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1496 - accuracy: 0.9427 - val_loss: 1.6674 - val_accuracy: 0.7714\n",
      "Epoch 954/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1789 - accuracy: 0.9247 - val_loss: 1.5709 - val_accuracy: 0.8286\n",
      "Epoch 955/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1695 - accuracy: 0.9462 - val_loss: 1.7192 - val_accuracy: 0.7143\n",
      "Epoch 956/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.1700 - accuracy: 0.9355 - val_loss: 1.5579 - val_accuracy: 0.8286\n",
      "Epoch 957/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1398 - accuracy: 0.9642 - val_loss: 1.6295 - val_accuracy: 0.8143\n",
      "Epoch 958/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1574 - accuracy: 0.9534 - val_loss: 1.6073 - val_accuracy: 0.8286\n",
      "Epoch 959/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1512 - accuracy: 0.9570 - val_loss: 1.6140 - val_accuracy: 0.8000\n",
      "Epoch 960/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.1573 - accuracy: 0.9462 - val_loss: 1.7161 - val_accuracy: 0.8286\n",
      "Epoch 961/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1718 - accuracy: 0.9319 - val_loss: 1.5960 - val_accuracy: 0.8000\n",
      "Epoch 962/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1634 - accuracy: 0.9498 - val_loss: 1.6275 - val_accuracy: 0.7429\n",
      "Epoch 963/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1523 - accuracy: 0.9498 - val_loss: 1.5924 - val_accuracy: 0.8286\n",
      "Epoch 964/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1552 - accuracy: 0.9319 - val_loss: 1.6375 - val_accuracy: 0.7286\n",
      "Epoch 965/1000\n",
      "279/279 [==============================] - 0s 71us/step - loss: 0.1690 - accuracy: 0.9355 - val_loss: 1.6449 - val_accuracy: 0.8000\n",
      "Epoch 966/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.1631 - accuracy: 0.9427 - val_loss: 1.5754 - val_accuracy: 0.8143\n",
      "Epoch 967/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1897 - accuracy: 0.9140 - val_loss: 1.6727 - val_accuracy: 0.7429\n",
      "Epoch 968/1000\n",
      "279/279 [==============================] - 0s 76us/step - loss: 0.1809 - accuracy: 0.9211 - val_loss: 1.7376 - val_accuracy: 0.8000\n",
      "Epoch 969/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1750 - accuracy: 0.9355 - val_loss: 1.6236 - val_accuracy: 0.8143\n",
      "Epoch 970/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1782 - accuracy: 0.9355 - val_loss: 1.5521 - val_accuracy: 0.7571\n",
      "Epoch 971/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.1594 - accuracy: 0.9534 - val_loss: 1.6714 - val_accuracy: 0.8143\n",
      "Epoch 972/1000\n",
      "279/279 [==============================] - 0s 67us/step - loss: 0.1844 - accuracy: 0.9247 - val_loss: 1.5258 - val_accuracy: 0.8286\n",
      "Epoch 973/1000\n",
      "279/279 [==============================] - 0s 85us/step - loss: 0.1860 - accuracy: 0.9140 - val_loss: 1.6614 - val_accuracy: 0.7286\n",
      "Epoch 974/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.2032 - accuracy: 0.9068 - val_loss: 1.5177 - val_accuracy: 0.7857\n",
      "Epoch 975/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.1593 - accuracy: 0.9427 - val_loss: 1.4453 - val_accuracy: 0.8000\n",
      "Epoch 976/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1524 - accuracy: 0.9355 - val_loss: 1.7893 - val_accuracy: 0.7429\n",
      "Epoch 977/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1701 - accuracy: 0.9319 - val_loss: 1.4887 - val_accuracy: 0.8000\n",
      "Epoch 978/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1530 - accuracy: 0.9498 - val_loss: 1.7240 - val_accuracy: 0.8143\n",
      "Epoch 979/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.1586 - accuracy: 0.9355 - val_loss: 1.6136 - val_accuracy: 0.7571\n",
      "Epoch 980/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.1869 - accuracy: 0.9211 - val_loss: 1.5925 - val_accuracy: 0.8286\n",
      "Epoch 981/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.1885 - accuracy: 0.9247 - val_loss: 1.6899 - val_accuracy: 0.7571\n",
      "Epoch 982/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1607 - accuracy: 0.9570 - val_loss: 1.6500 - val_accuracy: 0.8000\n",
      "Epoch 983/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.1501 - accuracy: 0.9570 - val_loss: 1.6730 - val_accuracy: 0.7857\n",
      "Epoch 984/1000\n",
      "279/279 [==============================] - 0s 86us/step - loss: 0.1555 - accuracy: 0.9462 - val_loss: 1.5944 - val_accuracy: 0.7857\n",
      "Epoch 985/1000\n",
      "279/279 [==============================] - 0s 97us/step - loss: 0.1625 - accuracy: 0.9427 - val_loss: 1.7724 - val_accuracy: 0.7857\n",
      "Epoch 986/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1681 - accuracy: 0.9247 - val_loss: 1.6731 - val_accuracy: 0.8000\n",
      "Epoch 987/1000\n",
      "279/279 [==============================] - 0s 81us/step - loss: 0.1639 - accuracy: 0.9427 - val_loss: 1.5206 - val_accuracy: 0.7714\n",
      "Epoch 988/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1976 - accuracy: 0.9247 - val_loss: 1.9739 - val_accuracy: 0.7000\n",
      "Epoch 989/1000\n",
      "279/279 [==============================] - 0s 68us/step - loss: 0.2028 - accuracy: 0.9140 - val_loss: 1.6338 - val_accuracy: 0.7571\n",
      "Epoch 990/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.2228 - accuracy: 0.9140 - val_loss: 1.6760 - val_accuracy: 0.7571\n",
      "Epoch 991/1000\n",
      "279/279 [==============================] - 0s 74us/step - loss: 0.1805 - accuracy: 0.9247 - val_loss: 1.5476 - val_accuracy: 0.7429\n",
      "Epoch 992/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1849 - accuracy: 0.9319 - val_loss: 1.4313 - val_accuracy: 0.7714\n",
      "Epoch 993/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1778 - accuracy: 0.9355 - val_loss: 1.9047 - val_accuracy: 0.6857\n",
      "Epoch 994/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1817 - accuracy: 0.9355 - val_loss: 1.5440 - val_accuracy: 0.7857\n",
      "Epoch 995/1000\n",
      "279/279 [==============================] - 0s 77us/step - loss: 0.1648 - accuracy: 0.9534 - val_loss: 1.5976 - val_accuracy: 0.8000\n",
      "Epoch 996/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1541 - accuracy: 0.9498 - val_loss: 1.5393 - val_accuracy: 0.7571\n",
      "Epoch 997/1000\n",
      "279/279 [==============================] - 0s 72us/step - loss: 0.1593 - accuracy: 0.9391 - val_loss: 1.6028 - val_accuracy: 0.8143\n",
      "Epoch 998/1000\n",
      "279/279 [==============================] - 0s 83us/step - loss: 0.1502 - accuracy: 0.9283 - val_loss: 1.6285 - val_accuracy: 0.8429\n",
      "Epoch 999/1000\n",
      "279/279 [==============================] - 0s 79us/step - loss: 0.1469 - accuracy: 0.9534 - val_loss: 1.5945 - val_accuracy: 0.8143\n",
      "Epoch 1000/1000\n",
      "279/279 [==============================] - 0s 75us/step - loss: 0.1337 - accuracy: 0.9642 - val_loss: 1.7021 - val_accuracy: 0.8286\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(X.shape[1], input_dim=X.shape[1], activation=\"tanh\"))\n",
    "model.add(Dense(150, activation=\"relu\"))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X, y, epochs=1000, validation_split = 0.2)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 10-30s   [0. 1. 0. 0. 0.]\n",
      "Predicted: 10-30s   [0.02 0.52 0.4  0.06 0.  ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "test_seq_number = 10\n",
    "\n",
    "ttf_labels = ['<10s', '10-30s', '30-60s', '>60s', '>90s']\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "prediction = y_pred[test_seq_number]\n",
    "expected = y_test[test_seq_number]\n",
    "\n",
    "print(\"Expected:\", ttf_labels[np.argmax(expected)], \" \", expected)\n",
    "print(\"Predicted:\", ttf_labels[np.argmax(prediction)], \" \", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  2,  1,  0,  0],\n",
       "       [ 4, 35,  2,  0,  0],\n",
       "       [ 3,  8, 40,  3,  1],\n",
       "       [ 0,  0,  3, 28,  1],\n",
       "       [ 2,  0,  3,  4, 19]], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "y_true_label = []\n",
    "y_pred_label = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    y_true_label.append(ttf_labels[np.argmax(y_test[i])])\n",
    "    y_pred_label.append(ttf_labels[np.argmax(y_pred[i])])\n",
    "\n",
    "\n",
    "confusion_matrix(y_true_label, y_pred_label, labels=ttf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at confustion matrix we can see that majority of the predictions is located on diagonal\n",
    "# which means that model is trained well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
